{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('telco2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No     1.0           No   \n",
       "1  5575-GNVDE    Male              0      No         No    34.0          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No     2.0          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No    45.0           No   \n",
       "4  9237-HQITU  Female              0      No         No     2.0          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0           Electronic check          29.85         29.85     No  \n",
       "1               Mailed check          56.95       1889.50     No  \n",
       "2               Mailed check          53.85        108.15    Yes  \n",
       "3  Bank transfer (automatic)          42.30           NaN     No  \n",
       "4           Electronic check          70.70        151.65    Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>7032.000000</td>\n",
       "      <td>7023.000000</td>\n",
       "      <td>7032.000000</td>\n",
       "      <td>7025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.162400</td>\n",
       "      <td>32.430158</td>\n",
       "      <td>64.798208</td>\n",
       "      <td>2282.239317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.368844</td>\n",
       "      <td>24.546817</td>\n",
       "      <td>30.085974</td>\n",
       "      <td>2266.150569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>18.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>35.587500</td>\n",
       "      <td>401.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>70.350000</td>\n",
       "      <td>1396.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>89.862500</td>\n",
       "      <td>3791.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>118.750000</td>\n",
       "      <td>8684.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeniorCitizen       tenure  MonthlyCharges  TotalCharges\n",
       "count    7032.000000  7023.000000     7032.000000   7025.000000\n",
       "mean        0.162400    32.430158       64.798208   2282.239317\n",
       "std         0.368844    24.546817       30.085974   2266.150569\n",
       "min         0.000000     1.000000       18.250000     18.800000\n",
       "25%         0.000000     9.000000       35.587500    401.500000\n",
       "50%         0.000000    29.000000       70.350000   1396.900000\n",
       "75%         0.000000    55.000000       89.862500   3791.600000\n",
       "max         1.000000    72.000000      118.750000   8684.800000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7032 entries, 0 to 7031\n",
      "Data columns (total 21 columns):\n",
      "customerID          7032 non-null object\n",
      "gender              7032 non-null object\n",
      "SeniorCitizen       7032 non-null int64\n",
      "Partner             7032 non-null object\n",
      "Dependents          7032 non-null object\n",
      "tenure              7023 non-null float64\n",
      "PhoneService        7032 non-null object\n",
      "MultipleLines       7032 non-null object\n",
      "InternetService     7032 non-null object\n",
      "OnlineSecurity      7032 non-null object\n",
      "OnlineBackup        7029 non-null object\n",
      "DeviceProtection    7025 non-null object\n",
      "TechSupport         7032 non-null object\n",
      "StreamingTV         7032 non-null object\n",
      "StreamingMovies     7032 non-null object\n",
      "Contract            7032 non-null object\n",
      "PaperlessBilling    7032 non-null object\n",
      "PaymentMethod       7032 non-null object\n",
      "MonthlyCharges      7032 non-null float64\n",
      "TotalCharges        7025 non-null float64\n",
      "Churn               7032 non-null object\n",
      "dtypes: float64(3), int64(1), object(17)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              9\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        3\n",
       "DeviceProtection    7\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        7\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        3\n",
       "DeviceProtection    7\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate out independent categorical variables for conversion into numerical\n",
    "df_catg=df.loc[:,('gender','Partner', 'Dependents','PhoneService', 'MultipleLines', \n",
    "                 'InternetService',    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling','PaymentMethod','SeniorCitizen')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num=df.loc[:,('tenure','MonthlyCharges','TotalCharges')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'] = df['Churn'].replace(to_replace =[\"No\",\"Yes\"], \n",
    "                 value =[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables into dummy coding\n",
    "df_dummy=pd.get_dummies(df_catg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_No</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_No</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No</th>\n",
       "      <th>...</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaperlessBilling_No</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  gender_Female  gender_Male  Partner_No  Partner_Yes  \\\n",
       "0              0              1            0           0            1   \n",
       "1              0              0            1           1            0   \n",
       "2              0              0            1           1            0   \n",
       "3              0              0            1           1            0   \n",
       "4              0              1            0           1            0   \n",
       "\n",
       "   Dependents_No  Dependents_Yes  PhoneService_No  PhoneService_Yes  \\\n",
       "0              1               0                1                 0   \n",
       "1              1               0                0                 1   \n",
       "2              1               0                0                 1   \n",
       "3              1               0                1                 0   \n",
       "4              1               0                0                 1   \n",
       "\n",
       "   MultipleLines_No  ...  StreamingMovies_Yes  Contract_Month-to-month  \\\n",
       "0                 0  ...                    0                        1   \n",
       "1                 1  ...                    0                        0   \n",
       "2                 1  ...                    0                        1   \n",
       "3                 0  ...                    0                        0   \n",
       "4                 1  ...                    0                        1   \n",
       "\n",
       "   Contract_One year  Contract_Two year  PaperlessBilling_No  \\\n",
       "0                  0                  0                    0   \n",
       "1                  1                  0                    1   \n",
       "2                  0                  0                    0   \n",
       "3                  1                  0                    1   \n",
       "4                  0                  0                    0   \n",
       "\n",
       "   PaperlessBilling_Yes  PaymentMethod_Bank transfer (automatic)  \\\n",
       "0                     1                                        0   \n",
       "1                     0                                        0   \n",
       "2                     1                                        0   \n",
       "3                     0                                        1   \n",
       "4                     1                                        0   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               1   \n",
       "\n",
       "   PaymentMethod_Mailed check  \n",
       "0                           0  \n",
       "1                           1  \n",
       "2                           1  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy.drop(columns=['Partner_No', 'Dependents_No','MultipleLines_No phone service',\n",
    "                               'OnlineSecurity_No internet service','OnlineBackup_No internet service',\n",
    "                               'TechSupport_No internet service','StreamingTV_No internet service',\n",
    "                               'StreamingMovies_No internet service','gender_Female','DeviceProtection_No internet service'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7032 entries, 0 to 7031\n",
      "Data columns (total 32 columns):\n",
      "SeniorCitizen                              7032 non-null int64\n",
      "gender_Male                                7032 non-null uint8\n",
      "Partner_Yes                                7032 non-null uint8\n",
      "Dependents_Yes                             7032 non-null uint8\n",
      "PhoneService_No                            7032 non-null uint8\n",
      "PhoneService_Yes                           7032 non-null uint8\n",
      "MultipleLines_No                           7032 non-null uint8\n",
      "MultipleLines_Yes                          7032 non-null uint8\n",
      "InternetService_DSL                        7032 non-null uint8\n",
      "InternetService_Fiber optic                7032 non-null uint8\n",
      "InternetService_No                         7032 non-null uint8\n",
      "OnlineSecurity_No                          7032 non-null uint8\n",
      "OnlineSecurity_Yes                         7032 non-null uint8\n",
      "OnlineBackup_No                            7032 non-null uint8\n",
      "OnlineBackup_Yes                           7032 non-null uint8\n",
      "DeviceProtection_No                        7032 non-null uint8\n",
      "DeviceProtection_Yes                       7032 non-null uint8\n",
      "TechSupport_No                             7032 non-null uint8\n",
      "TechSupport_Yes                            7032 non-null uint8\n",
      "StreamingTV_No                             7032 non-null uint8\n",
      "StreamingTV_Yes                            7032 non-null uint8\n",
      "StreamingMovies_No                         7032 non-null uint8\n",
      "StreamingMovies_Yes                        7032 non-null uint8\n",
      "Contract_Month-to-month                    7032 non-null uint8\n",
      "Contract_One year                          7032 non-null uint8\n",
      "Contract_Two year                          7032 non-null uint8\n",
      "PaperlessBilling_No                        7032 non-null uint8\n",
      "PaperlessBilling_Yes                       7032 non-null uint8\n",
      "PaymentMethod_Bank transfer (automatic)    7032 non-null uint8\n",
      "PaymentMethod_Credit card (automatic)      7032 non-null uint8\n",
      "PaymentMethod_Electronic check             7032 non-null uint8\n",
      "PaymentMethod_Mailed check                 7032 non-null uint8\n",
      "dtypes: int64(1), uint8(31)\n",
      "memory usage: 267.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_dummy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.concat([df_num,df_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 35)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df1, df['Churn'], test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5625, 35)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1407, 35)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5625,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1407,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 35\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 2\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    # Apply dropout to the first hidden layer\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    bn1 = tf.nn.selu(my_batch_norm_layer(hidden1_drop))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    bn2 = tf.nn.selu(my_batch_norm_layer(hidden2_drop))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.7022033\n",
      "1 Test accuracy: 0.7690121\n",
      "2 Test accuracy: 0.7754087\n",
      "3 Test accuracy: 0.76616913\n",
      "4 Test accuracy: 0.78678036\n",
      "5 Test accuracy: 0.7789623\n",
      "6 Test accuracy: 0.7761194\n",
      "7 Test accuracy: 0.77683014\n",
      "8 Test accuracy: 0.76830137\n",
      "9 Test accuracy: 0.76119405\n",
      "10 Test accuracy: 0.7761194\n",
      "11 Test accuracy: 0.77327645\n",
      "12 Test accuracy: 0.7711443\n",
      "13 Test accuracy: 0.771855\n",
      "14 Test accuracy: 0.76830137\n",
      "15 Test accuracy: 0.7590618\n",
      "16 Test accuracy: 0.75977254\n",
      "17 Test accuracy: 0.75124377\n",
      "18 Test accuracy: 0.76759064\n",
      "19 Test accuracy: 0.76616913\n",
      "20 Test accuracy: 0.7647477\n",
      "21 Test accuracy: 0.76687986\n",
      "22 Test accuracy: 0.7697228\n",
      "23 Test accuracy: 0.7583511\n",
      "24 Test accuracy: 0.7356077\n",
      "25 Test accuracy: 0.7633262\n",
      "26 Test accuracy: 0.75408673\n",
      "27 Test accuracy: 0.7583511\n",
      "28 Test accuracy: 0.75408673\n",
      "29 Test accuracy: 0.76616913\n",
      "30 Test accuracy: 0.7562189\n",
      "31 Test accuracy: 0.7633262\n",
      "32 Test accuracy: 0.75124377\n",
      "33 Test accuracy: 0.76687986\n",
      "34 Test accuracy: 0.7469794\n",
      "35 Test accuracy: 0.7498223\n",
      "36 Test accuracy: 0.76403695\n",
      "37 Test accuracy: 0.7519545\n",
      "38 Test accuracy: 0.7654584\n",
      "39 Test accuracy: 0.75692964\n",
      "40 Test accuracy: 0.7555082\n",
      "41 Test accuracy: 0.7590618\n",
      "42 Test accuracy: 0.75692964\n",
      "43 Test accuracy: 0.76830137\n",
      "44 Test accuracy: 0.74769014\n",
      "45 Test accuracy: 0.76759064\n",
      "46 Test accuracy: 0.7633262\n",
      "47 Test accuracy: 0.7626155\n",
      "48 Test accuracy: 0.7604833\n",
      "49 Test accuracy: 0.75977254\n",
      "50 Test accuracy: 0.75124377\n",
      "51 Test accuracy: 0.7555082\n",
      "52 Test accuracy: 0.74769014\n",
      "53 Test accuracy: 0.7498223\n",
      "54 Test accuracy: 0.7469794\n",
      "55 Test accuracy: 0.75692964\n",
      "56 Test accuracy: 0.7590618\n",
      "57 Test accuracy: 0.7619048\n",
      "58 Test accuracy: 0.7604833\n",
      "59 Test accuracy: 0.7604833\n",
      "60 Test accuracy: 0.75337595\n",
      "61 Test accuracy: 0.75977254\n",
      "62 Test accuracy: 0.7604833\n",
      "63 Test accuracy: 0.7604833\n",
      "64 Test accuracy: 0.7526652\n",
      "65 Test accuracy: 0.7562189\n",
      "66 Test accuracy: 0.7519545\n",
      "67 Test accuracy: 0.7583511\n",
      "68 Test accuracy: 0.74769014\n",
      "69 Test accuracy: 0.75053304\n",
      "70 Test accuracy: 0.75337595\n",
      "71 Test accuracy: 0.75408673\n",
      "72 Test accuracy: 0.7555082\n",
      "73 Test accuracy: 0.7555082\n",
      "74 Test accuracy: 0.7498223\n",
      "75 Test accuracy: 0.7519545\n",
      "76 Test accuracy: 0.75053304\n",
      "77 Test accuracy: 0.75479746\n",
      "78 Test accuracy: 0.7526652\n",
      "79 Test accuracy: 0.75337595\n",
      "80 Test accuracy: 0.7455579\n",
      "81 Test accuracy: 0.7526652\n",
      "82 Test accuracy: 0.7562189\n",
      "83 Test accuracy: 0.7555082\n",
      "84 Test accuracy: 0.74840087\n",
      "85 Test accuracy: 0.75408673\n",
      "86 Test accuracy: 0.7491116\n",
      "87 Test accuracy: 0.74840087\n",
      "88 Test accuracy: 0.75479746\n",
      "89 Test accuracy: 0.7526652\n",
      "90 Test accuracy: 0.7562189\n",
      "91 Test accuracy: 0.7434257\n",
      "92 Test accuracy: 0.74413645\n",
      "93 Test accuracy: 0.75053304\n",
      "94 Test accuracy: 0.75124377\n",
      "95 Test accuracy: 0.7498223\n",
      "96 Test accuracy: 0.74769014\n",
      "97 Test accuracy: 0.7498223\n",
      "98 Test accuracy: 0.75408673\n",
      "99 Test accuracy: 0.7519545\n"
     ]
    }
   ],
   "source": [
    "# Execution phase\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 194\n",
    "m = x_train.shape[0]\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    for i in range(0, m, batch_size):\n",
    "        X_batch = x_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "# When is_training is True the moving_mean and moving_variance need to be updated by running these commands\n",
    "# extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "# sess.run([train_op, extra_update_ops], ...)\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: x_test,\n",
    "                                                y: y_test})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'train/ExponentialDecay:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5625, 35)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.keras.initializers.VarianceScaling(\n",
    "    scale=1.0, mode='fan_avg', distribution='truncated_normal',\n",
    "    seed=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 300)               10800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 143,102\n",
      "Trainable params: 142,302\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1.add(tf.keras.Input(shape=(35)))\n",
    "model1.add(tf.keras.layers.Dense(300,kernel_initializer=he_init,activation=None))\n",
    "model1.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
    "model1.add(tf.keras.layers.Dense(300,kernel_initializer=he_init,activation=tf.nn.selu))\n",
    "model1.add(tf.keras.layers.Dropout(0.5))\n",
    "model1.add(tf.keras.layers.Dense(100,kernel_initializer=he_init,activation=None))\n",
    "model1.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
    "model1.add(tf.keras.layers.Dense(100,kernel_initializer=he_init,activation=tf.nn.selu))\n",
    "model1.add(tf.keras.layers.Dropout(0.5))\n",
    "model1.add(tf.keras.layers.Dense(2))\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5062 samples, validate on 563 samples\n",
      "Epoch 1/500\n",
      "5062/5062 [==============================] - 2s 377us/sample - loss: 0.8303 - acc: 0.6492 - val_loss: 0.4620 - val_acc: 0.7780\n",
      "Epoch 2/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.6194 - acc: 0.7228 - val_loss: 0.4645 - val_acc: 0.7744\n",
      "Epoch 3/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.5717 - acc: 0.7351 - val_loss: 0.4960 - val_acc: 0.7584\n",
      "Epoch 4/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.5344 - acc: 0.7485 - val_loss: 0.4825 - val_acc: 0.7744\n",
      "Epoch 5/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.5196 - acc: 0.7657 - val_loss: 0.4527 - val_acc: 0.8011\n",
      "Epoch 6/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.5024 - acc: 0.7697 - val_loss: 0.4368 - val_acc: 0.7940\n",
      "Epoch 7/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4910 - acc: 0.7720 - val_loss: 0.4439 - val_acc: 0.8117\n",
      "Epoch 8/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4863 - acc: 0.7695 - val_loss: 0.4324 - val_acc: 0.7975\n",
      "Epoch 9/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4828 - acc: 0.7677 - val_loss: 0.4751 - val_acc: 0.7904\n",
      "Epoch 10/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4739 - acc: 0.7789 - val_loss: 0.4287 - val_acc: 0.8064\n",
      "Epoch 11/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4613 - acc: 0.7900 - val_loss: 0.4419 - val_acc: 0.7993\n",
      "Epoch 12/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4656 - acc: 0.7821 - val_loss: 0.4323 - val_acc: 0.7904\n",
      "Epoch 13/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4619 - acc: 0.7876 - val_loss: 0.4238 - val_acc: 0.7993\n",
      "Epoch 14/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4564 - acc: 0.7825 - val_loss: 0.7145 - val_acc: 0.6163\n",
      "Epoch 15/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4647 - acc: 0.7827 - val_loss: 0.4304 - val_acc: 0.7975\n",
      "Epoch 16/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4414 - acc: 0.7945 - val_loss: 0.4649 - val_acc: 0.7567\n",
      "Epoch 17/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4564 - acc: 0.7853 - val_loss: 0.4315 - val_acc: 0.7975\n",
      "Epoch 18/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4475 - acc: 0.7886 - val_loss: 0.4366 - val_acc: 0.7940\n",
      "Epoch 19/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4478 - acc: 0.7918 - val_loss: 0.4581 - val_acc: 0.7851\n",
      "Epoch 20/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4387 - acc: 0.7942 - val_loss: 0.4955 - val_acc: 0.8011\n",
      "Epoch 21/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4427 - acc: 0.7912 - val_loss: 0.4467 - val_acc: 0.7762\n",
      "Epoch 22/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4423 - acc: 0.7940 - val_loss: 0.4296 - val_acc: 0.7940\n",
      "Epoch 23/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4435 - acc: 0.7930 - val_loss: 0.4154 - val_acc: 0.8082\n",
      "Epoch 24/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4405 - acc: 0.7995 - val_loss: 0.4354 - val_acc: 0.7886\n",
      "Epoch 25/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4399 - acc: 0.7983 - val_loss: 0.4199 - val_acc: 0.7993\n",
      "Epoch 26/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4362 - acc: 0.7989 - val_loss: 0.4198 - val_acc: 0.7975\n",
      "Epoch 27/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4428 - acc: 0.7949 - val_loss: 0.4291 - val_acc: 0.8011\n",
      "Epoch 28/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4370 - acc: 0.7963 - val_loss: 0.4694 - val_acc: 0.7655\n",
      "Epoch 29/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4424 - acc: 0.7920 - val_loss: 0.4802 - val_acc: 0.7407\n",
      "Epoch 30/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4453 - acc: 0.7955 - val_loss: 0.4142 - val_acc: 0.8028\n",
      "Epoch 31/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4338 - acc: 0.8054 - val_loss: 0.4170 - val_acc: 0.7940\n",
      "Epoch 32/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4404 - acc: 0.7965 - val_loss: 0.4201 - val_acc: 0.7940\n",
      "Epoch 33/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4367 - acc: 0.7973 - val_loss: 0.4500 - val_acc: 0.7815\n",
      "Epoch 34/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4344 - acc: 0.7991 - val_loss: 0.4222 - val_acc: 0.7993\n",
      "Epoch 35/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4321 - acc: 0.7987 - val_loss: 0.4133 - val_acc: 0.7975\n",
      "Epoch 36/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4418 - acc: 0.7963 - val_loss: 0.4425 - val_acc: 0.7922\n",
      "Epoch 37/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4335 - acc: 0.7997 - val_loss: 0.4125 - val_acc: 0.7922\n",
      "Epoch 38/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4364 - acc: 0.7981 - val_loss: 0.4176 - val_acc: 0.7904\n",
      "Epoch 39/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4334 - acc: 0.7953 - val_loss: 0.4699 - val_acc: 0.7886\n",
      "Epoch 40/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4344 - acc: 0.7961 - val_loss: 0.4201 - val_acc: 0.8028\n",
      "Epoch 41/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4344 - acc: 0.7938 - val_loss: 0.4143 - val_acc: 0.7922\n",
      "Epoch 42/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.4352 - acc: 0.7949 - val_loss: 0.4411 - val_acc: 0.8011\n",
      "Epoch 43/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4361 - acc: 0.8009 - val_loss: 0.4178 - val_acc: 0.7957\n",
      "Epoch 44/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4310 - acc: 0.7930 - val_loss: 0.4327 - val_acc: 0.7940\n",
      "Epoch 45/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4282 - acc: 0.8013 - val_loss: 0.4152 - val_acc: 0.7957\n",
      "Epoch 46/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4342 - acc: 0.7959 - val_loss: 0.4140 - val_acc: 0.7957\n",
      "Epoch 47/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4349 - acc: 0.7989 - val_loss: 0.4323 - val_acc: 0.7940\n",
      "Epoch 48/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4317 - acc: 0.8007 - val_loss: 0.4389 - val_acc: 0.7798\n",
      "Epoch 49/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4286 - acc: 0.8009 - val_loss: 0.4115 - val_acc: 0.8011\n",
      "Epoch 50/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4366 - acc: 0.8009 - val_loss: 0.4142 - val_acc: 0.7922\n",
      "Epoch 51/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4277 - acc: 0.8021 - val_loss: 0.4215 - val_acc: 0.7922\n",
      "Epoch 52/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4292 - acc: 0.8046 - val_loss: 0.4239 - val_acc: 0.8011\n",
      "Epoch 53/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4326 - acc: 0.7938 - val_loss: 0.4354 - val_acc: 0.7869\n",
      "Epoch 54/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4341 - acc: 0.7991 - val_loss: 0.4138 - val_acc: 0.7922\n",
      "Epoch 55/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4310 - acc: 0.8011 - val_loss: 0.4092 - val_acc: 0.8028\n",
      "Epoch 56/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4268 - acc: 0.7983 - val_loss: 0.4115 - val_acc: 0.8046\n",
      "Epoch 57/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4337 - acc: 0.7995 - val_loss: 0.4102 - val_acc: 0.7957\n",
      "Epoch 58/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4296 - acc: 0.8060 - val_loss: 0.4115 - val_acc: 0.8011\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4279 - acc: 0.8019 - val_loss: 0.4187 - val_acc: 0.8046\n",
      "Epoch 60/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4243 - acc: 0.8028 - val_loss: 0.4123 - val_acc: 0.7975\n",
      "Epoch 61/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4314 - acc: 0.7989 - val_loss: 0.4115 - val_acc: 0.7922\n",
      "Epoch 62/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4266 - acc: 0.7991 - val_loss: 0.4192 - val_acc: 0.8011\n",
      "Epoch 63/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4315 - acc: 0.8019 - val_loss: 0.4112 - val_acc: 0.7975\n",
      "Epoch 64/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4287 - acc: 0.8032 - val_loss: 0.4277 - val_acc: 0.8028\n",
      "Epoch 65/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4216 - acc: 0.8026 - val_loss: 0.4217 - val_acc: 0.7922\n",
      "Epoch 66/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4281 - acc: 0.8015 - val_loss: 0.4248 - val_acc: 0.7975\n",
      "Epoch 67/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4305 - acc: 0.8003 - val_loss: 0.4169 - val_acc: 0.7993\n",
      "Epoch 68/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4273 - acc: 0.7991 - val_loss: 0.4291 - val_acc: 0.7922\n",
      "Epoch 69/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4286 - acc: 0.7947 - val_loss: 0.4407 - val_acc: 0.7904\n",
      "Epoch 70/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4279 - acc: 0.7983 - val_loss: 0.4253 - val_acc: 0.7975\n",
      "Epoch 71/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4322 - acc: 0.8003 - val_loss: 0.4702 - val_acc: 0.7886\n",
      "Epoch 72/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4289 - acc: 0.8005 - val_loss: 0.4110 - val_acc: 0.7975\n",
      "Epoch 73/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4298 - acc: 0.7987 - val_loss: 0.4197 - val_acc: 0.7904\n",
      "Epoch 74/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4279 - acc: 0.8052 - val_loss: 0.4168 - val_acc: 0.7957\n",
      "Epoch 75/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4273 - acc: 0.8023 - val_loss: 0.4136 - val_acc: 0.7940\n",
      "Epoch 76/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4270 - acc: 0.8028 - val_loss: 0.4118 - val_acc: 0.7975\n",
      "Epoch 77/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4240 - acc: 0.8052 - val_loss: 0.4097 - val_acc: 0.7975\n",
      "Epoch 78/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4247 - acc: 0.7997 - val_loss: 0.4179 - val_acc: 0.8046\n",
      "Epoch 79/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4219 - acc: 0.8054 - val_loss: 0.4214 - val_acc: 0.7922\n",
      "Epoch 80/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4294 - acc: 0.7993 - val_loss: 0.4160 - val_acc: 0.7957\n",
      "Epoch 81/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4282 - acc: 0.8009 - val_loss: 0.4364 - val_acc: 0.7993\n",
      "Epoch 82/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4255 - acc: 0.8015 - val_loss: 0.4157 - val_acc: 0.8011\n",
      "Epoch 83/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4313 - acc: 0.7997 - val_loss: 0.4142 - val_acc: 0.7957\n",
      "Epoch 84/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4256 - acc: 0.8032 - val_loss: 0.4200 - val_acc: 0.7957\n",
      "Epoch 85/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4297 - acc: 0.7999 - val_loss: 0.4193 - val_acc: 0.7993\n",
      "Epoch 86/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4256 - acc: 0.7995 - val_loss: 0.4130 - val_acc: 0.7940\n",
      "Epoch 87/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4247 - acc: 0.8082 - val_loss: 0.4176 - val_acc: 0.7975\n",
      "Epoch 88/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4276 - acc: 0.8032 - val_loss: 0.4158 - val_acc: 0.7886\n",
      "Epoch 89/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4251 - acc: 0.8026 - val_loss: 0.4165 - val_acc: 0.7957\n",
      "Epoch 90/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4317 - acc: 0.7985 - val_loss: 0.4245 - val_acc: 0.7940\n",
      "Epoch 91/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4326 - acc: 0.7999 - val_loss: 0.4170 - val_acc: 0.8046\n",
      "Epoch 92/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4261 - acc: 0.8015 - val_loss: 0.4097 - val_acc: 0.7940\n",
      "Epoch 93/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4246 - acc: 0.8023 - val_loss: 0.4098 - val_acc: 0.8028\n",
      "Epoch 94/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4262 - acc: 0.8019 - val_loss: 0.4098 - val_acc: 0.7957\n",
      "Epoch 95/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4246 - acc: 0.8017 - val_loss: 0.4174 - val_acc: 0.7975\n",
      "Epoch 96/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4237 - acc: 0.8023 - val_loss: 0.4253 - val_acc: 0.7922\n",
      "Epoch 97/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4281 - acc: 0.8007 - val_loss: 0.4130 - val_acc: 0.7904\n",
      "Epoch 98/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4260 - acc: 0.7993 - val_loss: 0.4352 - val_acc: 0.7975\n",
      "Epoch 99/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4285 - acc: 0.8023 - val_loss: 0.4100 - val_acc: 0.7975\n",
      "Epoch 100/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4327 - acc: 0.7947 - val_loss: 0.4182 - val_acc: 0.7940\n",
      "Epoch 101/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4269 - acc: 0.8017 - val_loss: 0.4246 - val_acc: 0.7940\n",
      "Epoch 102/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4268 - acc: 0.7979 - val_loss: 0.4111 - val_acc: 0.8046\n",
      "Epoch 103/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4274 - acc: 0.7999 - val_loss: 0.4153 - val_acc: 0.7993\n",
      "Epoch 104/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4246 - acc: 0.8034 - val_loss: 0.4123 - val_acc: 0.7940\n",
      "Epoch 105/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4271 - acc: 0.8048 - val_loss: 0.4246 - val_acc: 0.7922\n",
      "Epoch 106/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4232 - acc: 0.8019 - val_loss: 0.4131 - val_acc: 0.7940\n",
      "Epoch 107/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4244 - acc: 0.8040 - val_loss: 0.4132 - val_acc: 0.8011\n",
      "Epoch 108/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4280 - acc: 0.8007 - val_loss: 0.4155 - val_acc: 0.7993\n",
      "Epoch 109/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4283 - acc: 0.8062 - val_loss: 0.4164 - val_acc: 0.7975\n",
      "Epoch 110/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4251 - acc: 0.7999 - val_loss: 0.4259 - val_acc: 0.7993\n",
      "Epoch 111/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4271 - acc: 0.7995 - val_loss: 0.4180 - val_acc: 0.7957\n",
      "Epoch 112/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4278 - acc: 0.7989 - val_loss: 0.4121 - val_acc: 0.7975\n",
      "Epoch 113/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4277 - acc: 0.8028 - val_loss: 0.4167 - val_acc: 0.7975\n",
      "Epoch 114/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4256 - acc: 0.8044 - val_loss: 0.4287 - val_acc: 0.7886\n",
      "Epoch 115/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4232 - acc: 0.8024 - val_loss: 0.4224 - val_acc: 0.7993\n",
      "Epoch 116/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4230 - acc: 0.8005 - val_loss: 0.4191 - val_acc: 0.7993\n",
      "Epoch 117/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4228 - acc: 0.8058 - val_loss: 0.4111 - val_acc: 0.7993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4216 - acc: 0.8052 - val_loss: 0.4091 - val_acc: 0.8011\n",
      "Epoch 119/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4230 - acc: 0.8066 - val_loss: 0.4155 - val_acc: 0.8011\n",
      "Epoch 120/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4220 - acc: 0.8030 - val_loss: 0.4380 - val_acc: 0.7922\n",
      "Epoch 121/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4268 - acc: 0.8017 - val_loss: 0.4202 - val_acc: 0.7922\n",
      "Epoch 122/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4268 - acc: 0.8017 - val_loss: 0.4349 - val_acc: 0.7922\n",
      "Epoch 123/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4251 - acc: 0.8062 - val_loss: 0.4170 - val_acc: 0.7940\n",
      "Epoch 124/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4247 - acc: 0.8019 - val_loss: 0.4198 - val_acc: 0.7904\n",
      "Epoch 125/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4241 - acc: 0.8044 - val_loss: 0.4234 - val_acc: 0.7940\n",
      "Epoch 126/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4254 - acc: 0.8013 - val_loss: 0.4160 - val_acc: 0.7940\n",
      "Epoch 127/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4252 - acc: 0.8005 - val_loss: 0.4328 - val_acc: 0.7886\n",
      "Epoch 128/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4253 - acc: 0.8044 - val_loss: 0.4299 - val_acc: 0.7940\n",
      "Epoch 129/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4285 - acc: 0.8052 - val_loss: 0.4227 - val_acc: 0.7922\n",
      "Epoch 130/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4240 - acc: 0.8013 - val_loss: 0.4235 - val_acc: 0.7957\n",
      "Epoch 131/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4247 - acc: 0.8003 - val_loss: 0.4433 - val_acc: 0.7833\n",
      "Epoch 132/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4225 - acc: 0.8054 - val_loss: 0.4212 - val_acc: 0.7957\n",
      "Epoch 133/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4237 - acc: 0.8032 - val_loss: 0.4134 - val_acc: 0.7940\n",
      "Epoch 134/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4311 - acc: 0.8003 - val_loss: 0.4257 - val_acc: 0.7975\n",
      "Epoch 135/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4279 - acc: 0.7981 - val_loss: 0.4143 - val_acc: 0.7975\n",
      "Epoch 136/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4203 - acc: 0.8036 - val_loss: 0.4128 - val_acc: 0.7940\n",
      "Epoch 137/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4237 - acc: 0.8048 - val_loss: 0.4190 - val_acc: 0.7957\n",
      "Epoch 138/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4248 - acc: 0.7999 - val_loss: 0.4189 - val_acc: 0.7957\n",
      "Epoch 139/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4235 - acc: 0.8028 - val_loss: 0.4100 - val_acc: 0.8028\n",
      "Epoch 140/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4203 - acc: 0.8032 - val_loss: 0.4093 - val_acc: 0.7993\n",
      "Epoch 141/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4231 - acc: 0.7983 - val_loss: 0.4204 - val_acc: 0.7957\n",
      "Epoch 142/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4254 - acc: 0.8007 - val_loss: 0.4171 - val_acc: 0.7957\n",
      "Epoch 143/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4236 - acc: 0.8038 - val_loss: 0.4104 - val_acc: 0.7922\n",
      "Epoch 144/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4236 - acc: 0.8019 - val_loss: 0.4122 - val_acc: 0.8011\n",
      "Epoch 145/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4219 - acc: 0.8034 - val_loss: 0.4342 - val_acc: 0.7744\n",
      "Epoch 146/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4270 - acc: 0.8017 - val_loss: 0.4208 - val_acc: 0.7940\n",
      "Epoch 147/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4231 - acc: 0.8046 - val_loss: 0.4111 - val_acc: 0.7975\n",
      "Epoch 148/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4264 - acc: 0.7979 - val_loss: 0.4157 - val_acc: 0.7975\n",
      "Epoch 149/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4292 - acc: 0.7965 - val_loss: 0.4141 - val_acc: 0.7940\n",
      "Epoch 150/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4219 - acc: 0.8058 - val_loss: 0.4125 - val_acc: 0.7975\n",
      "Epoch 151/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4261 - acc: 0.7991 - val_loss: 0.4183 - val_acc: 0.7940\n",
      "Epoch 152/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4245 - acc: 0.7995 - val_loss: 0.4205 - val_acc: 0.7922\n",
      "Epoch 153/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4281 - acc: 0.8013 - val_loss: 0.4155 - val_acc: 0.7957\n",
      "Epoch 154/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4221 - acc: 0.8005 - val_loss: 0.4798 - val_acc: 0.7371\n",
      "Epoch 155/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4329 - acc: 0.7997 - val_loss: 0.4255 - val_acc: 0.7922\n",
      "Epoch 156/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4282 - acc: 0.7977 - val_loss: 0.4067 - val_acc: 0.7993\n",
      "Epoch 157/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4236 - acc: 0.8048 - val_loss: 0.4063 - val_acc: 0.8082\n",
      "Epoch 158/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4245 - acc: 0.8023 - val_loss: 0.4112 - val_acc: 0.7975\n",
      "Epoch 159/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4238 - acc: 0.8023 - val_loss: 0.4058 - val_acc: 0.7993\n",
      "Epoch 160/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4232 - acc: 0.8021 - val_loss: 0.4115 - val_acc: 0.8011\n",
      "Epoch 161/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4219 - acc: 0.8013 - val_loss: 0.4104 - val_acc: 0.7922\n",
      "Epoch 162/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4240 - acc: 0.8003 - val_loss: 0.4226 - val_acc: 0.7957\n",
      "Epoch 163/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4197 - acc: 0.8038 - val_loss: 0.4205 - val_acc: 0.7993\n",
      "Epoch 164/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4231 - acc: 0.8034 - val_loss: 0.4113 - val_acc: 0.7993\n",
      "Epoch 165/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4208 - acc: 0.8017 - val_loss: 0.4097 - val_acc: 0.8011\n",
      "Epoch 166/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4228 - acc: 0.7991 - val_loss: 0.4156 - val_acc: 0.8011\n",
      "Epoch 167/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4203 - acc: 0.8034 - val_loss: 0.4112 - val_acc: 0.7922\n",
      "Epoch 168/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4197 - acc: 0.8040 - val_loss: 0.4300 - val_acc: 0.7940\n",
      "Epoch 169/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4291 - acc: 0.7979 - val_loss: 0.4197 - val_acc: 0.7940\n",
      "Epoch 170/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4217 - acc: 0.8048 - val_loss: 0.4094 - val_acc: 0.7975\n",
      "Epoch 171/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4268 - acc: 0.8021 - val_loss: 0.4100 - val_acc: 0.7957\n",
      "Epoch 172/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4221 - acc: 0.8024 - val_loss: 0.4113 - val_acc: 0.7957\n",
      "Epoch 173/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4219 - acc: 0.8021 - val_loss: 0.4183 - val_acc: 0.7922\n",
      "Epoch 174/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4236 - acc: 0.8021 - val_loss: 0.4085 - val_acc: 0.7957\n",
      "Epoch 175/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4196 - acc: 0.8050 - val_loss: 0.4052 - val_acc: 0.8011\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4242 - acc: 0.8026 - val_loss: 0.4211 - val_acc: 0.7957\n",
      "Epoch 177/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4225 - acc: 0.8048 - val_loss: 0.4060 - val_acc: 0.8011\n",
      "Epoch 178/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4253 - acc: 0.8011 - val_loss: 0.4124 - val_acc: 0.7993\n",
      "Epoch 179/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4246 - acc: 0.8026 - val_loss: 0.4056 - val_acc: 0.7957\n",
      "Epoch 180/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4215 - acc: 0.8034 - val_loss: 0.4191 - val_acc: 0.7940\n",
      "Epoch 181/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4270 - acc: 0.8007 - val_loss: 0.4079 - val_acc: 0.7957\n",
      "Epoch 182/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4210 - acc: 0.8024 - val_loss: 0.4060 - val_acc: 0.7922\n",
      "Epoch 183/500\n",
      "5062/5062 [==============================] - 0s 62us/sample - loss: 0.4262 - acc: 0.8011 - val_loss: 0.4192 - val_acc: 0.7940\n",
      "Epoch 184/500\n",
      "5062/5062 [==============================] - 0s 61us/sample - loss: 0.4204 - acc: 0.8026 - val_loss: 0.4040 - val_acc: 0.8082\n",
      "Epoch 185/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4222 - acc: 0.8001 - val_loss: 0.4103 - val_acc: 0.7940\n",
      "Epoch 186/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4203 - acc: 0.8036 - val_loss: 0.4114 - val_acc: 0.7957\n",
      "Epoch 187/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4220 - acc: 0.8030 - val_loss: 0.4233 - val_acc: 0.7922\n",
      "Epoch 188/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4236 - acc: 0.8034 - val_loss: 0.4118 - val_acc: 0.7957\n",
      "Epoch 189/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4210 - acc: 0.8040 - val_loss: 0.4125 - val_acc: 0.7975\n",
      "Epoch 190/500\n",
      "5062/5062 [==============================] - 0s 60us/sample - loss: 0.4193 - acc: 0.8009 - val_loss: 0.4232 - val_acc: 0.7957\n",
      "Epoch 191/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.4265 - acc: 0.7989 - val_loss: 0.4128 - val_acc: 0.8028\n",
      "Epoch 192/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4214 - acc: 0.7989 - val_loss: 0.4424 - val_acc: 0.7975\n",
      "Epoch 193/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4232 - acc: 0.8042 - val_loss: 0.4089 - val_acc: 0.7993\n",
      "Epoch 194/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4228 - acc: 0.8024 - val_loss: 0.4351 - val_acc: 0.7851\n",
      "Epoch 195/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.4214 - acc: 0.8015 - val_loss: 0.4182 - val_acc: 0.7975\n",
      "Epoch 196/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4304 - acc: 0.7993 - val_loss: 0.4221 - val_acc: 0.7904\n",
      "Epoch 197/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4225 - acc: 0.8019 - val_loss: 0.4078 - val_acc: 0.8011\n",
      "Epoch 198/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4228 - acc: 0.8001 - val_loss: 0.4093 - val_acc: 0.8011\n",
      "Epoch 199/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4227 - acc: 0.8054 - val_loss: 0.4205 - val_acc: 0.7869\n",
      "Epoch 200/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4255 - acc: 0.8001 - val_loss: 0.4268 - val_acc: 0.7993\n",
      "Epoch 201/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4223 - acc: 0.8046 - val_loss: 0.4580 - val_acc: 0.7993\n",
      "Epoch 202/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4255 - acc: 0.8048 - val_loss: 0.4044 - val_acc: 0.8011\n",
      "Epoch 203/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4247 - acc: 0.8042 - val_loss: 0.4052 - val_acc: 0.7975\n",
      "Epoch 204/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4233 - acc: 0.8017 - val_loss: 0.4039 - val_acc: 0.8011\n",
      "Epoch 205/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4217 - acc: 0.8052 - val_loss: 0.4571 - val_acc: 0.7762\n",
      "Epoch 206/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4247 - acc: 0.8015 - val_loss: 0.4143 - val_acc: 0.8011\n",
      "Epoch 207/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4228 - acc: 0.8013 - val_loss: 0.4217 - val_acc: 0.7957\n",
      "Epoch 208/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4221 - acc: 0.8019 - val_loss: 0.4108 - val_acc: 0.7940\n",
      "Epoch 209/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4216 - acc: 0.8046 - val_loss: 0.4189 - val_acc: 0.7957\n",
      "Epoch 210/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4239 - acc: 0.8015 - val_loss: 0.4173 - val_acc: 0.7975\n",
      "Epoch 211/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4195 - acc: 0.8036 - val_loss: 0.4266 - val_acc: 0.7798\n",
      "Epoch 212/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4230 - acc: 0.8005 - val_loss: 0.4066 - val_acc: 0.8011\n",
      "Epoch 213/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4197 - acc: 0.8015 - val_loss: 0.4083 - val_acc: 0.7993\n",
      "Epoch 214/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4212 - acc: 0.8028 - val_loss: 0.4108 - val_acc: 0.7993\n",
      "Epoch 215/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4201 - acc: 0.8034 - val_loss: 0.4040 - val_acc: 0.7993\n",
      "Epoch 216/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4226 - acc: 0.8052 - val_loss: 0.4471 - val_acc: 0.7940\n",
      "Epoch 217/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4191 - acc: 0.8034 - val_loss: 0.4295 - val_acc: 0.7886\n",
      "Epoch 218/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4223 - acc: 0.7997 - val_loss: 0.4098 - val_acc: 0.7940\n",
      "Epoch 219/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4230 - acc: 0.8040 - val_loss: 0.4076 - val_acc: 0.7993\n",
      "Epoch 220/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4255 - acc: 0.7995 - val_loss: 0.4377 - val_acc: 0.7993\n",
      "Epoch 221/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4186 - acc: 0.8038 - val_loss: 0.4356 - val_acc: 0.7940\n",
      "Epoch 222/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4208 - acc: 0.7967 - val_loss: 0.4035 - val_acc: 0.7975\n",
      "Epoch 223/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4210 - acc: 0.8054 - val_loss: 0.4099 - val_acc: 0.7993\n",
      "Epoch 224/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4275 - acc: 0.7995 - val_loss: 0.4025 - val_acc: 0.8011\n",
      "Epoch 225/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4203 - acc: 0.8040 - val_loss: 0.4098 - val_acc: 0.8011\n",
      "Epoch 226/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4223 - acc: 0.8023 - val_loss: 0.4190 - val_acc: 0.8011\n",
      "Epoch 227/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4245 - acc: 0.7999 - val_loss: 0.4080 - val_acc: 0.7993\n",
      "Epoch 228/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4193 - acc: 0.8060 - val_loss: 0.4036 - val_acc: 0.7993\n",
      "Epoch 229/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4203 - acc: 0.8003 - val_loss: 0.4075 - val_acc: 0.7993\n",
      "Epoch 230/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4221 - acc: 0.8005 - val_loss: 0.4306 - val_acc: 0.7851\n",
      "Epoch 231/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4215 - acc: 0.8042 - val_loss: 0.4186 - val_acc: 0.8046\n",
      "Epoch 232/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4211 - acc: 0.8013 - val_loss: 0.4148 - val_acc: 0.7940\n",
      "Epoch 233/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4234 - acc: 0.7995 - val_loss: 0.4159 - val_acc: 0.8028\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4251 - acc: 0.8001 - val_loss: 0.4202 - val_acc: 0.7975\n",
      "Epoch 235/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4199 - acc: 0.8044 - val_loss: 0.4082 - val_acc: 0.7993\n",
      "Epoch 236/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4186 - acc: 0.8072 - val_loss: 0.4031 - val_acc: 0.7993\n",
      "Epoch 237/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4253 - acc: 0.7993 - val_loss: 0.4231 - val_acc: 0.7904\n",
      "Epoch 238/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4264 - acc: 0.8007 - val_loss: 0.4026 - val_acc: 0.8011\n",
      "Epoch 239/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4224 - acc: 0.8032 - val_loss: 0.4059 - val_acc: 0.8028\n",
      "Epoch 240/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4239 - acc: 0.8013 - val_loss: 0.4024 - val_acc: 0.8064\n",
      "Epoch 241/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4192 - acc: 0.8026 - val_loss: 0.4070 - val_acc: 0.7993\n",
      "Epoch 242/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4203 - acc: 0.7999 - val_loss: 0.4092 - val_acc: 0.8046\n",
      "Epoch 243/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4194 - acc: 0.8028 - val_loss: 0.4076 - val_acc: 0.8011\n",
      "Epoch 244/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4201 - acc: 0.8028 - val_loss: 0.4050 - val_acc: 0.7940\n",
      "Epoch 245/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4203 - acc: 0.8050 - val_loss: 0.4026 - val_acc: 0.8011\n",
      "Epoch 246/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4201 - acc: 0.8028 - val_loss: 0.4040 - val_acc: 0.7975\n",
      "Epoch 247/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4142 - acc: 0.8036 - val_loss: 0.4030 - val_acc: 0.8011\n",
      "Epoch 248/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4202 - acc: 0.8003 - val_loss: 0.4020 - val_acc: 0.8011\n",
      "Epoch 249/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4204 - acc: 0.8028 - val_loss: 0.4072 - val_acc: 0.8011\n",
      "Epoch 250/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4194 - acc: 0.8019 - val_loss: 0.4188 - val_acc: 0.7957\n",
      "Epoch 251/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4220 - acc: 0.7987 - val_loss: 0.4237 - val_acc: 0.8011\n",
      "Epoch 252/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4186 - acc: 0.8023 - val_loss: 0.4013 - val_acc: 0.8011\n",
      "Epoch 253/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4211 - acc: 0.8005 - val_loss: 0.4062 - val_acc: 0.7993\n",
      "Epoch 254/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4211 - acc: 0.8015 - val_loss: 0.4006 - val_acc: 0.8028\n",
      "Epoch 255/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4174 - acc: 0.8080 - val_loss: 0.4013 - val_acc: 0.8028\n",
      "Epoch 256/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4209 - acc: 0.8040 - val_loss: 0.4035 - val_acc: 0.7957\n",
      "Epoch 257/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4198 - acc: 0.7975 - val_loss: 0.4039 - val_acc: 0.8011\n",
      "Epoch 258/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4202 - acc: 0.8030 - val_loss: 0.4078 - val_acc: 0.7993\n",
      "Epoch 259/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4214 - acc: 0.8024 - val_loss: 0.4162 - val_acc: 0.7975\n",
      "Epoch 260/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4191 - acc: 0.8074 - val_loss: 0.4203 - val_acc: 0.7975\n",
      "Epoch 261/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4201 - acc: 0.8007 - val_loss: 0.4086 - val_acc: 0.8011\n",
      "Epoch 262/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4225 - acc: 0.7997 - val_loss: 0.4480 - val_acc: 0.7851\n",
      "Epoch 263/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4183 - acc: 0.8062 - val_loss: 0.4038 - val_acc: 0.7993\n",
      "Epoch 264/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4188 - acc: 0.7981 - val_loss: 0.4050 - val_acc: 0.7957\n",
      "Epoch 265/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4189 - acc: 0.8026 - val_loss: 0.4040 - val_acc: 0.8046\n",
      "Epoch 266/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4193 - acc: 0.8054 - val_loss: 0.4127 - val_acc: 0.7975\n",
      "Epoch 267/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4187 - acc: 0.8005 - val_loss: 0.4061 - val_acc: 0.8028\n",
      "Epoch 268/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4208 - acc: 0.7995 - val_loss: 0.4261 - val_acc: 0.7975\n",
      "Epoch 269/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4244 - acc: 0.8023 - val_loss: 0.4332 - val_acc: 0.7993\n",
      "Epoch 270/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4198 - acc: 0.8058 - val_loss: 0.4043 - val_acc: 0.8011\n",
      "Epoch 271/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4159 - acc: 0.8032 - val_loss: 0.4021 - val_acc: 0.7993\n",
      "Epoch 272/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4218 - acc: 0.8024 - val_loss: 0.4029 - val_acc: 0.8011\n",
      "Epoch 273/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4178 - acc: 0.8030 - val_loss: 0.4005 - val_acc: 0.7975\n",
      "Epoch 274/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4213 - acc: 0.8011 - val_loss: 0.4146 - val_acc: 0.8046\n",
      "Epoch 275/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4196 - acc: 0.8056 - val_loss: 0.4160 - val_acc: 0.7975\n",
      "Epoch 276/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4195 - acc: 0.8048 - val_loss: 0.4209 - val_acc: 0.7975\n",
      "Epoch 277/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4216 - acc: 0.7997 - val_loss: 0.4044 - val_acc: 0.7993\n",
      "Epoch 278/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4185 - acc: 0.8054 - val_loss: 0.4026 - val_acc: 0.7993\n",
      "Epoch 279/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4169 - acc: 0.7989 - val_loss: 0.4113 - val_acc: 0.7975\n",
      "Epoch 280/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4199 - acc: 0.8028 - val_loss: 0.4132 - val_acc: 0.8011\n",
      "Epoch 281/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4167 - acc: 0.8078 - val_loss: 0.4107 - val_acc: 0.7975\n",
      "Epoch 282/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4199 - acc: 0.8021 - val_loss: 0.4078 - val_acc: 0.8011\n",
      "Epoch 283/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4191 - acc: 0.8015 - val_loss: 0.4046 - val_acc: 0.8011\n",
      "Epoch 284/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4203 - acc: 0.8005 - val_loss: 0.4006 - val_acc: 0.8011\n",
      "Epoch 285/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4186 - acc: 0.8052 - val_loss: 0.3995 - val_acc: 0.8011\n",
      "Epoch 286/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4179 - acc: 0.8026 - val_loss: 0.4025 - val_acc: 0.8028\n",
      "Epoch 287/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4205 - acc: 0.8034 - val_loss: 0.4241 - val_acc: 0.8011\n",
      "Epoch 288/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4205 - acc: 0.8052 - val_loss: 0.4037 - val_acc: 0.7975\n",
      "Epoch 289/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4209 - acc: 0.8011 - val_loss: 0.4013 - val_acc: 0.7957\n",
      "Epoch 290/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4211 - acc: 0.8009 - val_loss: 0.4007 - val_acc: 0.7993\n",
      "Epoch 291/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4178 - acc: 0.8032 - val_loss: 0.4072 - val_acc: 0.8011\n",
      "Epoch 292/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4199 - acc: 0.8028 - val_loss: 0.4080 - val_acc: 0.8028\n",
      "Epoch 293/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4167 - acc: 0.8048 - val_loss: 0.4091 - val_acc: 0.8011\n",
      "Epoch 294/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4195 - acc: 0.8052 - val_loss: 0.4103 - val_acc: 0.8011\n",
      "Epoch 295/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4182 - acc: 0.8064 - val_loss: 0.4071 - val_acc: 0.8046\n",
      "Epoch 296/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4161 - acc: 0.8046 - val_loss: 0.4223 - val_acc: 0.7975\n",
      "Epoch 297/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4174 - acc: 0.8011 - val_loss: 0.4246 - val_acc: 0.7975\n",
      "Epoch 298/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4158 - acc: 0.8058 - val_loss: 0.4015 - val_acc: 0.7993\n",
      "Epoch 299/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4180 - acc: 0.8068 - val_loss: 0.4020 - val_acc: 0.8011\n",
      "Epoch 300/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4177 - acc: 0.8040 - val_loss: 0.4077 - val_acc: 0.8011\n",
      "Epoch 301/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4174 - acc: 0.8009 - val_loss: 0.4106 - val_acc: 0.7993\n",
      "Epoch 302/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4247 - acc: 0.8042 - val_loss: 0.4493 - val_acc: 0.7975\n",
      "Epoch 303/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4224 - acc: 0.8056 - val_loss: 0.4051 - val_acc: 0.8011\n",
      "Epoch 304/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4200 - acc: 0.7993 - val_loss: 0.4041 - val_acc: 0.8028\n",
      "Epoch 305/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4195 - acc: 0.8036 - val_loss: 0.4039 - val_acc: 0.8011\n",
      "Epoch 306/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4171 - acc: 0.8046 - val_loss: 0.4056 - val_acc: 0.7993\n",
      "Epoch 307/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4193 - acc: 0.8042 - val_loss: 0.4072 - val_acc: 0.8011\n",
      "Epoch 308/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4142 - acc: 0.8056 - val_loss: 0.4072 - val_acc: 0.8011\n",
      "Epoch 309/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4151 - acc: 0.8056 - val_loss: 0.4039 - val_acc: 0.8011\n",
      "Epoch 310/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4172 - acc: 0.8024 - val_loss: 0.4177 - val_acc: 0.7940\n",
      "Epoch 311/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4195 - acc: 0.8026 - val_loss: 0.4122 - val_acc: 0.7993\n",
      "Epoch 312/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4161 - acc: 0.8076 - val_loss: 0.4693 - val_acc: 0.7975\n",
      "Epoch 313/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4272 - acc: 0.8001 - val_loss: 0.4313 - val_acc: 0.7886\n",
      "Epoch 314/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4193 - acc: 0.8038 - val_loss: 0.4020 - val_acc: 0.7993\n",
      "Epoch 315/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4191 - acc: 0.8062 - val_loss: 0.4093 - val_acc: 0.7993\n",
      "Epoch 316/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4179 - acc: 0.8064 - val_loss: 0.4212 - val_acc: 0.8064\n",
      "Epoch 317/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4196 - acc: 0.8046 - val_loss: 0.4055 - val_acc: 0.7993\n",
      "Epoch 318/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4178 - acc: 0.8054 - val_loss: 0.4120 - val_acc: 0.8011\n",
      "Epoch 319/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4224 - acc: 0.8024 - val_loss: 0.4085 - val_acc: 0.8011\n",
      "Epoch 320/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4218 - acc: 0.8038 - val_loss: 0.4077 - val_acc: 0.8011\n",
      "Epoch 321/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4196 - acc: 0.8005 - val_loss: 0.4026 - val_acc: 0.8011\n",
      "Epoch 322/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4182 - acc: 0.8052 - val_loss: 0.4058 - val_acc: 0.7975\n",
      "Epoch 323/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4168 - acc: 0.8015 - val_loss: 0.4044 - val_acc: 0.7993\n",
      "Epoch 324/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4191 - acc: 0.8060 - val_loss: 0.4328 - val_acc: 0.7869\n",
      "Epoch 325/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4192 - acc: 0.8080 - val_loss: 0.4039 - val_acc: 0.8028\n",
      "Epoch 326/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4191 - acc: 0.8032 - val_loss: 0.4109 - val_acc: 0.8011\n",
      "Epoch 327/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4183 - acc: 0.8013 - val_loss: 0.4082 - val_acc: 0.7993\n",
      "Epoch 328/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4167 - acc: 0.8068 - val_loss: 0.4016 - val_acc: 0.8028\n",
      "Epoch 329/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4188 - acc: 0.8003 - val_loss: 0.4077 - val_acc: 0.8011\n",
      "Epoch 330/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4182 - acc: 0.8026 - val_loss: 0.4028 - val_acc: 0.8011\n",
      "Epoch 331/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4163 - acc: 0.8052 - val_loss: 0.4038 - val_acc: 0.7993\n",
      "Epoch 332/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4189 - acc: 0.7993 - val_loss: 0.4081 - val_acc: 0.8028\n",
      "Epoch 333/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4191 - acc: 0.8013 - val_loss: 0.4499 - val_acc: 0.7726\n",
      "Epoch 334/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4153 - acc: 0.7995 - val_loss: 0.4026 - val_acc: 0.8011\n",
      "Epoch 335/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4141 - acc: 0.8084 - val_loss: 0.4175 - val_acc: 0.7993\n",
      "Epoch 336/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4184 - acc: 0.8080 - val_loss: 0.4030 - val_acc: 0.8046\n",
      "Epoch 337/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4159 - acc: 0.8032 - val_loss: 0.4311 - val_acc: 0.7922\n",
      "Epoch 338/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4176 - acc: 0.8044 - val_loss: 0.4228 - val_acc: 0.7940\n",
      "Epoch 339/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4157 - acc: 0.8038 - val_loss: 0.4587 - val_acc: 0.7957\n",
      "Epoch 340/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4191 - acc: 0.8066 - val_loss: 0.4408 - val_acc: 0.7869\n",
      "Epoch 341/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4204 - acc: 0.7951 - val_loss: 0.4064 - val_acc: 0.8046\n",
      "Epoch 342/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4167 - acc: 0.8038 - val_loss: 0.4300 - val_acc: 0.7957\n",
      "Epoch 343/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4160 - acc: 0.8003 - val_loss: 0.4104 - val_acc: 0.8028\n",
      "Epoch 344/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4199 - acc: 0.8050 - val_loss: 0.4407 - val_acc: 0.7993\n",
      "Epoch 345/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4233 - acc: 0.8015 - val_loss: 0.4574 - val_acc: 0.8046\n",
      "Epoch 346/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4165 - acc: 0.8086 - val_loss: 0.4052 - val_acc: 0.7975\n",
      "Epoch 347/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4176 - acc: 0.8023 - val_loss: 0.4022 - val_acc: 0.8028\n",
      "Epoch 348/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4141 - acc: 0.8044 - val_loss: 0.4028 - val_acc: 0.7993\n",
      "Epoch 349/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4143 - acc: 0.8048 - val_loss: 0.4059 - val_acc: 0.7993\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4165 - acc: 0.8017 - val_loss: 0.4052 - val_acc: 0.8064\n",
      "Epoch 351/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4177 - acc: 0.8060 - val_loss: 0.4093 - val_acc: 0.7993\n",
      "Epoch 352/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4207 - acc: 0.7975 - val_loss: 0.4858 - val_acc: 0.7229\n",
      "Epoch 353/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4233 - acc: 0.8003 - val_loss: 0.4068 - val_acc: 0.8011\n",
      "Epoch 354/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4224 - acc: 0.8028 - val_loss: 0.4308 - val_acc: 0.7869\n",
      "Epoch 355/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4181 - acc: 0.8058 - val_loss: 0.4049 - val_acc: 0.8011\n",
      "Epoch 356/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4178 - acc: 0.8048 - val_loss: 0.4078 - val_acc: 0.8028\n",
      "Epoch 357/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4182 - acc: 0.8070 - val_loss: 0.4312 - val_acc: 0.7975\n",
      "Epoch 358/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4183 - acc: 0.8058 - val_loss: 0.4052 - val_acc: 0.8011\n",
      "Epoch 359/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4159 - acc: 0.8058 - val_loss: 0.4027 - val_acc: 0.7993\n",
      "Epoch 360/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4180 - acc: 0.8032 - val_loss: 0.4025 - val_acc: 0.7975\n",
      "Epoch 361/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4145 - acc: 0.8023 - val_loss: 0.4242 - val_acc: 0.7975\n",
      "Epoch 362/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4152 - acc: 0.8090 - val_loss: 0.4215 - val_acc: 0.7940\n",
      "Epoch 363/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4159 - acc: 0.8032 - val_loss: 0.4116 - val_acc: 0.8064\n",
      "Epoch 364/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4110 - acc: 0.8094 - val_loss: 0.4034 - val_acc: 0.8011\n",
      "Epoch 365/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4192 - acc: 0.8028 - val_loss: 0.4113 - val_acc: 0.8028\n",
      "Epoch 366/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4173 - acc: 0.8028 - val_loss: 0.4036 - val_acc: 0.8028\n",
      "Epoch 367/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4161 - acc: 0.8038 - val_loss: 0.4008 - val_acc: 0.7975\n",
      "Epoch 368/500\n",
      "5062/5062 [==============================] - 0s 46us/sample - loss: 0.4190 - acc: 0.8038 - val_loss: 0.4350 - val_acc: 0.7869\n",
      "Epoch 369/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4141 - acc: 0.8082 - val_loss: 0.4110 - val_acc: 0.8046\n",
      "Epoch 370/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4178 - acc: 0.8026 - val_loss: 0.4319 - val_acc: 0.7886\n",
      "Epoch 371/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4208 - acc: 0.8019 - val_loss: 0.4353 - val_acc: 0.8046\n",
      "Epoch 372/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4192 - acc: 0.8054 - val_loss: 0.4133 - val_acc: 0.8046\n",
      "Epoch 373/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4190 - acc: 0.8005 - val_loss: 0.4107 - val_acc: 0.7957\n",
      "Epoch 374/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4186 - acc: 0.8009 - val_loss: 0.4117 - val_acc: 0.7993\n",
      "Epoch 375/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4188 - acc: 0.8026 - val_loss: 0.4071 - val_acc: 0.8011\n",
      "Epoch 376/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4173 - acc: 0.8038 - val_loss: 0.4060 - val_acc: 0.8011\n",
      "Epoch 377/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4200 - acc: 0.8040 - val_loss: 0.4108 - val_acc: 0.7940\n",
      "Epoch 378/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4174 - acc: 0.8062 - val_loss: 0.4188 - val_acc: 0.8046\n",
      "Epoch 379/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4151 - acc: 0.8054 - val_loss: 0.4071 - val_acc: 0.7975\n",
      "Epoch 380/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4148 - acc: 0.8070 - val_loss: 0.4044 - val_acc: 0.8028\n",
      "Epoch 381/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4170 - acc: 0.8050 - val_loss: 0.4203 - val_acc: 0.7904\n",
      "Epoch 382/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4142 - acc: 0.8050 - val_loss: 0.4074 - val_acc: 0.7993\n",
      "Epoch 383/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4155 - acc: 0.8040 - val_loss: 0.4133 - val_acc: 0.7975\n",
      "Epoch 384/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4151 - acc: 0.8038 - val_loss: 0.4049 - val_acc: 0.8064\n",
      "Epoch 385/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4171 - acc: 0.8050 - val_loss: 0.4048 - val_acc: 0.7993\n",
      "Epoch 386/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4183 - acc: 0.8032 - val_loss: 0.4032 - val_acc: 0.8011\n",
      "Epoch 387/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4207 - acc: 0.8009 - val_loss: 0.4108 - val_acc: 0.7975\n",
      "Epoch 388/500\n",
      "5062/5062 [==============================] - 0s 58us/sample - loss: 0.4161 - acc: 0.8042 - val_loss: 0.4048 - val_acc: 0.7993\n",
      "Epoch 389/500\n",
      "5062/5062 [==============================] - 0s 60us/sample - loss: 0.4141 - acc: 0.8040 - val_loss: 0.4437 - val_acc: 0.7940\n",
      "Epoch 390/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4211 - acc: 0.8024 - val_loss: 0.4172 - val_acc: 0.7957\n",
      "Epoch 391/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4165 - acc: 0.8038 - val_loss: 0.4421 - val_acc: 0.7940\n",
      "Epoch 392/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4226 - acc: 0.8023 - val_loss: 0.4120 - val_acc: 0.8011\n",
      "Epoch 393/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4147 - acc: 0.8030 - val_loss: 0.4295 - val_acc: 0.7922\n",
      "Epoch 394/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4217 - acc: 0.7989 - val_loss: 0.4115 - val_acc: 0.8011\n",
      "Epoch 395/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4166 - acc: 0.7997 - val_loss: 0.4074 - val_acc: 0.8011\n",
      "Epoch 396/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4185 - acc: 0.8050 - val_loss: 0.4059 - val_acc: 0.8028\n",
      "Epoch 397/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4168 - acc: 0.8024 - val_loss: 0.4165 - val_acc: 0.7993\n",
      "Epoch 398/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4168 - acc: 0.8058 - val_loss: 0.4155 - val_acc: 0.8028\n",
      "Epoch 399/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4161 - acc: 0.8017 - val_loss: 0.4906 - val_acc: 0.7194\n",
      "Epoch 400/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4186 - acc: 0.8070 - val_loss: 0.4280 - val_acc: 0.8011\n",
      "Epoch 401/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4124 - acc: 0.8068 - val_loss: 0.4148 - val_acc: 0.7922\n",
      "Epoch 402/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4168 - acc: 0.8054 - val_loss: 0.4095 - val_acc: 0.8082\n",
      "Epoch 403/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4184 - acc: 0.8046 - val_loss: 0.4501 - val_acc: 0.7780\n",
      "Epoch 404/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4164 - acc: 0.8030 - val_loss: 0.4121 - val_acc: 0.8099\n",
      "Epoch 405/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4142 - acc: 0.8040 - val_loss: 0.4196 - val_acc: 0.8046\n",
      "Epoch 406/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4171 - acc: 0.8038 - val_loss: 0.4067 - val_acc: 0.7993\n",
      "Epoch 407/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4186 - acc: 0.8058 - val_loss: 0.4109 - val_acc: 0.8028\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4176 - acc: 0.8024 - val_loss: 0.4372 - val_acc: 0.7975\n",
      "Epoch 409/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4189 - acc: 0.8046 - val_loss: 0.4084 - val_acc: 0.8046\n",
      "Epoch 410/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4167 - acc: 0.8024 - val_loss: 0.4090 - val_acc: 0.7957\n",
      "Epoch 411/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4186 - acc: 0.8040 - val_loss: 0.4050 - val_acc: 0.7993\n",
      "Epoch 412/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4169 - acc: 0.8052 - val_loss: 0.4034 - val_acc: 0.8046\n",
      "Epoch 413/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4169 - acc: 0.8032 - val_loss: 0.4280 - val_acc: 0.8064\n",
      "Epoch 414/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4170 - acc: 0.8056 - val_loss: 0.4062 - val_acc: 0.7957\n",
      "Epoch 415/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4159 - acc: 0.8058 - val_loss: 0.4286 - val_acc: 0.8011\n",
      "Epoch 416/500\n",
      "5062/5062 [==============================] - 0s 58us/sample - loss: 0.4154 - acc: 0.8005 - val_loss: 0.4077 - val_acc: 0.7975\n",
      "Epoch 417/500\n",
      "5062/5062 [==============================] - 0s 61us/sample - loss: 0.4178 - acc: 0.8048 - val_loss: 0.4068 - val_acc: 0.7993\n",
      "Epoch 418/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4172 - acc: 0.8052 - val_loss: 0.4322 - val_acc: 0.7957\n",
      "Epoch 419/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4146 - acc: 0.8032 - val_loss: 0.4369 - val_acc: 0.7957\n",
      "Epoch 420/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4167 - acc: 0.8026 - val_loss: 0.4385 - val_acc: 0.7975\n",
      "Epoch 421/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4172 - acc: 0.8017 - val_loss: 0.4034 - val_acc: 0.7993\n",
      "Epoch 422/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4174 - acc: 0.8013 - val_loss: 0.4078 - val_acc: 0.8028\n",
      "Epoch 423/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4161 - acc: 0.8070 - val_loss: 0.4300 - val_acc: 0.7957\n",
      "Epoch 424/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4133 - acc: 0.8052 - val_loss: 0.4358 - val_acc: 0.7851\n",
      "Epoch 425/500\n",
      "5062/5062 [==============================] - 0s 63us/sample - loss: 0.4196 - acc: 0.8005 - val_loss: 0.4231 - val_acc: 0.7940\n",
      "Epoch 426/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4126 - acc: 0.8072 - val_loss: 0.4054 - val_acc: 0.7957\n",
      "Epoch 427/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4141 - acc: 0.8028 - val_loss: 0.4068 - val_acc: 0.8064\n",
      "Epoch 428/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4135 - acc: 0.8058 - val_loss: 0.4077 - val_acc: 0.8064\n",
      "Epoch 429/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4120 - acc: 0.8072 - val_loss: 0.4121 - val_acc: 0.8064\n",
      "Epoch 430/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4154 - acc: 0.8048 - val_loss: 0.4218 - val_acc: 0.7957\n",
      "Epoch 431/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4170 - acc: 0.8026 - val_loss: 0.4305 - val_acc: 0.8046\n",
      "Epoch 432/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4156 - acc: 0.8060 - val_loss: 0.4268 - val_acc: 0.7940\n",
      "Epoch 433/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4209 - acc: 0.8021 - val_loss: 0.4034 - val_acc: 0.7957\n",
      "Epoch 434/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4157 - acc: 0.8017 - val_loss: 0.4100 - val_acc: 0.8082\n",
      "Epoch 435/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4133 - acc: 0.8082 - val_loss: 0.4065 - val_acc: 0.7993\n",
      "Epoch 436/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4168 - acc: 0.8072 - val_loss: 0.4196 - val_acc: 0.7993\n",
      "Epoch 437/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4198 - acc: 0.8042 - val_loss: 0.4112 - val_acc: 0.8046\n",
      "Epoch 438/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4187 - acc: 0.8030 - val_loss: 0.4153 - val_acc: 0.8028\n",
      "Epoch 439/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4172 - acc: 0.8024 - val_loss: 0.4118 - val_acc: 0.8064\n",
      "Epoch 440/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4161 - acc: 0.8058 - val_loss: 0.4272 - val_acc: 0.7993\n",
      "Epoch 441/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4190 - acc: 0.8019 - val_loss: 0.4361 - val_acc: 0.7975\n",
      "Epoch 442/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4154 - acc: 0.8036 - val_loss: 0.4098 - val_acc: 0.8117\n",
      "Epoch 443/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4178 - acc: 0.7993 - val_loss: 0.4093 - val_acc: 0.8011\n",
      "Epoch 444/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4201 - acc: 0.8028 - val_loss: 0.4095 - val_acc: 0.8135\n",
      "Epoch 445/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4175 - acc: 0.7987 - val_loss: 0.4222 - val_acc: 0.8046\n",
      "Epoch 446/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4163 - acc: 0.8068 - val_loss: 0.4102 - val_acc: 0.8082\n",
      "Epoch 447/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4120 - acc: 0.8032 - val_loss: 0.4082 - val_acc: 0.8082\n",
      "Epoch 448/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4148 - acc: 0.8021 - val_loss: 0.4222 - val_acc: 0.8011\n",
      "Epoch 449/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4171 - acc: 0.8050 - val_loss: 0.4260 - val_acc: 0.8046\n",
      "Epoch 450/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4146 - acc: 0.8046 - val_loss: 0.4112 - val_acc: 0.8046\n",
      "Epoch 451/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4143 - acc: 0.8088 - val_loss: 0.4308 - val_acc: 0.7975\n",
      "Epoch 452/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4147 - acc: 0.8040 - val_loss: 0.4175 - val_acc: 0.7993\n",
      "Epoch 453/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4201 - acc: 0.8026 - val_loss: 0.4103 - val_acc: 0.7975\n",
      "Epoch 454/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4131 - acc: 0.8034 - val_loss: 0.4060 - val_acc: 0.8046\n",
      "Epoch 455/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4138 - acc: 0.8032 - val_loss: 0.4046 - val_acc: 0.7993\n",
      "Epoch 456/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4172 - acc: 0.8050 - val_loss: 0.4067 - val_acc: 0.8082\n",
      "Epoch 457/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4116 - acc: 0.8082 - val_loss: 0.4106 - val_acc: 0.8046\n",
      "Epoch 458/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4180 - acc: 0.8076 - val_loss: 0.4142 - val_acc: 0.8028\n",
      "Epoch 459/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4132 - acc: 0.8034 - val_loss: 0.4067 - val_acc: 0.8011\n",
      "Epoch 460/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4197 - acc: 0.8032 - val_loss: 0.4278 - val_acc: 0.7886\n",
      "Epoch 461/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4220 - acc: 0.8013 - val_loss: 0.4267 - val_acc: 0.7940\n",
      "Epoch 462/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4144 - acc: 0.8023 - val_loss: 0.4215 - val_acc: 0.8046\n",
      "Epoch 463/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4203 - acc: 0.8040 - val_loss: 0.4339 - val_acc: 0.7957\n",
      "Epoch 464/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4171 - acc: 0.7997 - val_loss: 0.4118 - val_acc: 0.8011\n",
      "Epoch 465/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4158 - acc: 0.8052 - val_loss: 0.4059 - val_acc: 0.8046\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4169 - acc: 0.8052 - val_loss: 0.4216 - val_acc: 0.7922\n",
      "Epoch 467/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4148 - acc: 0.8060 - val_loss: 0.4138 - val_acc: 0.8028\n",
      "Epoch 468/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4145 - acc: 0.8040 - val_loss: 0.4075 - val_acc: 0.7975\n",
      "Epoch 469/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4178 - acc: 0.8088 - val_loss: 0.4186 - val_acc: 0.8028\n",
      "Epoch 470/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4125 - acc: 0.8070 - val_loss: 0.4070 - val_acc: 0.8028\n",
      "Epoch 471/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4181 - acc: 0.8013 - val_loss: 0.4040 - val_acc: 0.7993\n",
      "Epoch 472/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4158 - acc: 0.8048 - val_loss: 0.4211 - val_acc: 0.7957\n",
      "Epoch 473/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4145 - acc: 0.8092 - val_loss: 0.4102 - val_acc: 0.8046\n",
      "Epoch 474/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4144 - acc: 0.8074 - val_loss: 0.4068 - val_acc: 0.8064\n",
      "Epoch 475/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4142 - acc: 0.8064 - val_loss: 0.4137 - val_acc: 0.8028\n",
      "Epoch 476/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4135 - acc: 0.8048 - val_loss: 0.4227 - val_acc: 0.7940\n",
      "Epoch 477/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4182 - acc: 0.8050 - val_loss: 0.4086 - val_acc: 0.7940\n",
      "Epoch 478/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4139 - acc: 0.8066 - val_loss: 0.4100 - val_acc: 0.8064\n",
      "Epoch 479/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4160 - acc: 0.8046 - val_loss: 0.4059 - val_acc: 0.8046\n",
      "Epoch 480/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4138 - acc: 0.8011 - val_loss: 0.4072 - val_acc: 0.7993\n",
      "Epoch 481/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4126 - acc: 0.8082 - val_loss: 0.4287 - val_acc: 0.7851\n",
      "Epoch 482/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4181 - acc: 0.7975 - val_loss: 0.4083 - val_acc: 0.8064\n",
      "Epoch 483/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4142 - acc: 0.8048 - val_loss: 0.4056 - val_acc: 0.8011\n",
      "Epoch 484/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4129 - acc: 0.8019 - val_loss: 0.4076 - val_acc: 0.8011\n",
      "Epoch 485/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4133 - acc: 0.8068 - val_loss: 0.4078 - val_acc: 0.8099\n",
      "Epoch 486/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4144 - acc: 0.8050 - val_loss: 0.4075 - val_acc: 0.7993\n",
      "Epoch 487/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4141 - acc: 0.8015 - val_loss: 0.4061 - val_acc: 0.8028\n",
      "Epoch 488/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4149 - acc: 0.8021 - val_loss: 0.4093 - val_acc: 0.8028\n",
      "Epoch 489/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4199 - acc: 0.8015 - val_loss: 0.4059 - val_acc: 0.7993\n",
      "Epoch 490/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4131 - acc: 0.8048 - val_loss: 0.4094 - val_acc: 0.8028\n",
      "Epoch 491/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4146 - acc: 0.8048 - val_loss: 0.4140 - val_acc: 0.8028\n",
      "Epoch 492/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4150 - acc: 0.8028 - val_loss: 0.4039 - val_acc: 0.7993\n",
      "Epoch 493/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4145 - acc: 0.8054 - val_loss: 0.4047 - val_acc: 0.7993\n",
      "Epoch 494/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4159 - acc: 0.8038 - val_loss: 0.4095 - val_acc: 0.8028\n",
      "Epoch 495/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4108 - acc: 0.8092 - val_loss: 0.4058 - val_acc: 0.8011\n",
      "Epoch 496/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4146 - acc: 0.8056 - val_loss: 0.4165 - val_acc: 0.8028\n",
      "Epoch 497/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4163 - acc: 0.8050 - val_loss: 0.4148 - val_acc: 0.8011\n",
      "Epoch 498/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4145 - acc: 0.8032 - val_loss: 0.4114 - val_acc: 0.7975\n",
      "Epoch 499/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4115 - acc: 0.8026 - val_loss: 0.4224 - val_acc: 0.7869\n",
      "Epoch 500/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4155 - acc: 0.8001 - val_loss: 0.4091 - val_acc: 0.8064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3baa016ac8>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, epochs=500, batch_size=194, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 - 0s - loss: 0.4185 - acc: 0.8074\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model1.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model1.history.history['acc'])\n",
    "plt.plot(model1.history.history['val_acc'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model1.history.history['loss'])\n",
    "plt.plot(model1.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_transformer = QuantileTransformer(n_quantiles=100, output_distribution='normal', random_state=4)\n",
    "df_num1 = quantile_transformer.fit_transform(df.loc[:,('tenure','MonthlyCharges','TotalCharges')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f3bb3ceb748>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bb3c04cc0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3bb3c33e10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bb3bef0f0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_num1 = pd.DataFrame(df_num1, columns = ['tenure','MonthlyCharges','TotalCharges'])\n",
    "df_num1.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.concat([df_num1,df_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 35)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(df2, df['Churn'], test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 300)               10800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 143,102\n",
      "Trainable params: 142,302\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(tf.keras.Input(shape=(35)))\n",
    "model2.add(tf.keras.layers.Dense(300,kernel_initializer=he_init,activation=None))\n",
    "model2.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
    "model2.add(tf.keras.layers.Dense(300,kernel_initializer=he_init,activation=tf.nn.selu))\n",
    "model2.add(tf.keras.layers.Dropout(0.5))\n",
    "model2.add(tf.keras.layers.Dense(100,kernel_initializer=he_init,activation=None))\n",
    "model2.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
    "model2.add(tf.keras.layers.Dense(100,kernel_initializer=he_init,activation=tf.nn.selu))\n",
    "model2.add(tf.keras.layers.Dropout(0.5))\n",
    "model2.add(tf.keras.layers.Dense(2))\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5062 samples, validate on 563 samples\n",
      "Epoch 1/500\n",
      "5062/5062 [==============================] - 2s 358us/sample - loss: 0.7261 - acc: 0.6948 - val_loss: 0.4919 - val_acc: 0.7922\n",
      "Epoch 2/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.5880 - acc: 0.7424 - val_loss: 0.4275 - val_acc: 0.7869\n",
      "Epoch 3/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.5225 - acc: 0.7590 - val_loss: 0.4124 - val_acc: 0.7904\n",
      "Epoch 4/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.5020 - acc: 0.7699 - val_loss: 0.4329 - val_acc: 0.7869\n",
      "Epoch 5/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4869 - acc: 0.7758 - val_loss: 0.4106 - val_acc: 0.7957\n",
      "Epoch 6/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4580 - acc: 0.7827 - val_loss: 0.4103 - val_acc: 0.7904\n",
      "Epoch 7/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4527 - acc: 0.7845 - val_loss: 0.4095 - val_acc: 0.7922\n",
      "Epoch 8/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4489 - acc: 0.7902 - val_loss: 0.4070 - val_acc: 0.7904\n",
      "Epoch 9/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4469 - acc: 0.7884 - val_loss: 0.4099 - val_acc: 0.7922\n",
      "Epoch 10/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4430 - acc: 0.7898 - val_loss: 0.4055 - val_acc: 0.7975\n",
      "Epoch 11/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4382 - acc: 0.7918 - val_loss: 0.4041 - val_acc: 0.7886\n",
      "Epoch 12/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4291 - acc: 0.7963 - val_loss: 0.4032 - val_acc: 0.7940\n",
      "Epoch 13/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4412 - acc: 0.7924 - val_loss: 0.4042 - val_acc: 0.7851\n",
      "Epoch 14/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4325 - acc: 0.7947 - val_loss: 0.4050 - val_acc: 0.7993\n",
      "Epoch 15/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4309 - acc: 0.7945 - val_loss: 0.4083 - val_acc: 0.7886\n",
      "Epoch 16/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4324 - acc: 0.7961 - val_loss: 0.4057 - val_acc: 0.7886\n",
      "Epoch 17/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4269 - acc: 0.7944 - val_loss: 0.4094 - val_acc: 0.8046\n",
      "Epoch 18/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4265 - acc: 0.7965 - val_loss: 0.4052 - val_acc: 0.7922\n",
      "Epoch 19/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4238 - acc: 0.8009 - val_loss: 0.4023 - val_acc: 0.7869\n",
      "Epoch 20/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4247 - acc: 0.7981 - val_loss: 0.4071 - val_acc: 0.7886\n",
      "Epoch 21/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4247 - acc: 0.7991 - val_loss: 0.4070 - val_acc: 0.8028\n",
      "Epoch 22/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4199 - acc: 0.8011 - val_loss: 0.4050 - val_acc: 0.7993\n",
      "Epoch 23/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4172 - acc: 0.8036 - val_loss: 0.4031 - val_acc: 0.7922\n",
      "Epoch 24/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4193 - acc: 0.8038 - val_loss: 0.4027 - val_acc: 0.7922\n",
      "Epoch 25/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4215 - acc: 0.8030 - val_loss: 0.4042 - val_acc: 0.7975\n",
      "Epoch 26/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4166 - acc: 0.8062 - val_loss: 0.4069 - val_acc: 0.7922\n",
      "Epoch 27/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4200 - acc: 0.7969 - val_loss: 0.4053 - val_acc: 0.8011\n",
      "Epoch 28/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4220 - acc: 0.7989 - val_loss: 0.4068 - val_acc: 0.7886\n",
      "Epoch 29/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4154 - acc: 0.8050 - val_loss: 0.4078 - val_acc: 0.7869\n",
      "Epoch 30/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4140 - acc: 0.8064 - val_loss: 0.4054 - val_acc: 0.7886\n",
      "Epoch 31/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4135 - acc: 0.8054 - val_loss: 0.4047 - val_acc: 0.7957\n",
      "Epoch 32/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4166 - acc: 0.8017 - val_loss: 0.4031 - val_acc: 0.7780\n",
      "Epoch 33/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4151 - acc: 0.8042 - val_loss: 0.4016 - val_acc: 0.7957\n",
      "Epoch 34/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4152 - acc: 0.7997 - val_loss: 0.4014 - val_acc: 0.8011\n",
      "Epoch 35/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4187 - acc: 0.8001 - val_loss: 0.4015 - val_acc: 0.7957\n",
      "Epoch 36/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4123 - acc: 0.8064 - val_loss: 0.4094 - val_acc: 0.7975\n",
      "Epoch 37/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4162 - acc: 0.8070 - val_loss: 0.4104 - val_acc: 0.8011\n",
      "Epoch 38/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4176 - acc: 0.8023 - val_loss: 0.4106 - val_acc: 0.7975\n",
      "Epoch 39/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4183 - acc: 0.8052 - val_loss: 0.4099 - val_acc: 0.7940\n",
      "Epoch 40/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4129 - acc: 0.8064 - val_loss: 0.4019 - val_acc: 0.7975\n",
      "Epoch 41/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4133 - acc: 0.8052 - val_loss: 0.4016 - val_acc: 0.7975\n",
      "Epoch 42/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4123 - acc: 0.8046 - val_loss: 0.4065 - val_acc: 0.8046\n",
      "Epoch 43/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4117 - acc: 0.8026 - val_loss: 0.4027 - val_acc: 0.8011\n",
      "Epoch 44/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4146 - acc: 0.8036 - val_loss: 0.4003 - val_acc: 0.8011\n",
      "Epoch 45/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4113 - acc: 0.8054 - val_loss: 0.4038 - val_acc: 0.7940\n",
      "Epoch 46/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4131 - acc: 0.8030 - val_loss: 0.4055 - val_acc: 0.7869\n",
      "Epoch 47/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4113 - acc: 0.8060 - val_loss: 0.4060 - val_acc: 0.7904\n",
      "Epoch 48/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4102 - acc: 0.8088 - val_loss: 0.4087 - val_acc: 0.7957\n",
      "Epoch 49/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4139 - acc: 0.8038 - val_loss: 0.4054 - val_acc: 0.7886\n",
      "Epoch 50/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4134 - acc: 0.8013 - val_loss: 0.4041 - val_acc: 0.8011\n",
      "Epoch 51/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4063 - acc: 0.8044 - val_loss: 0.4035 - val_acc: 0.7975\n",
      "Epoch 52/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4083 - acc: 0.8080 - val_loss: 0.4001 - val_acc: 0.7957\n",
      "Epoch 53/500\n",
      "5062/5062 [==============================] - 0s 46us/sample - loss: 0.4112 - acc: 0.8066 - val_loss: 0.4025 - val_acc: 0.7904\n",
      "Epoch 54/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4122 - acc: 0.8111 - val_loss: 0.4028 - val_acc: 0.7886\n",
      "Epoch 55/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4061 - acc: 0.8082 - val_loss: 0.4027 - val_acc: 0.7957\n",
      "Epoch 56/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4100 - acc: 0.8040 - val_loss: 0.4045 - val_acc: 0.7922\n",
      "Epoch 57/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4125 - acc: 0.8044 - val_loss: 0.4072 - val_acc: 0.7833\n",
      "Epoch 58/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4125 - acc: 0.8084 - val_loss: 0.4081 - val_acc: 0.7957\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4112 - acc: 0.8038 - val_loss: 0.4055 - val_acc: 0.7904\n",
      "Epoch 60/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4073 - acc: 0.8050 - val_loss: 0.4012 - val_acc: 0.7904\n",
      "Epoch 61/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4070 - acc: 0.8078 - val_loss: 0.4043 - val_acc: 0.7869\n",
      "Epoch 62/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4082 - acc: 0.8044 - val_loss: 0.4047 - val_acc: 0.7922\n",
      "Epoch 63/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4117 - acc: 0.8090 - val_loss: 0.4050 - val_acc: 0.7940\n",
      "Epoch 64/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4091 - acc: 0.8054 - val_loss: 0.4067 - val_acc: 0.7833\n",
      "Epoch 65/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4026 - acc: 0.8135 - val_loss: 0.4070 - val_acc: 0.7993\n",
      "Epoch 66/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4084 - acc: 0.8046 - val_loss: 0.4043 - val_acc: 0.7975\n",
      "Epoch 67/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4072 - acc: 0.8074 - val_loss: 0.4073 - val_acc: 0.7922\n",
      "Epoch 68/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4038 - acc: 0.8086 - val_loss: 0.4069 - val_acc: 0.7940\n",
      "Epoch 69/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4069 - acc: 0.8076 - val_loss: 0.4076 - val_acc: 0.7904\n",
      "Epoch 70/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4075 - acc: 0.8125 - val_loss: 0.4048 - val_acc: 0.7904\n",
      "Epoch 71/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4105 - acc: 0.8062 - val_loss: 0.4024 - val_acc: 0.7975\n",
      "Epoch 72/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4053 - acc: 0.8109 - val_loss: 0.4053 - val_acc: 0.7957\n",
      "Epoch 73/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4045 - acc: 0.8090 - val_loss: 0.4045 - val_acc: 0.7940\n",
      "Epoch 74/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4036 - acc: 0.8074 - val_loss: 0.4063 - val_acc: 0.7940\n",
      "Epoch 75/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4080 - acc: 0.8088 - val_loss: 0.4046 - val_acc: 0.7975\n",
      "Epoch 76/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4055 - acc: 0.8165 - val_loss: 0.4027 - val_acc: 0.7922\n",
      "Epoch 77/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4066 - acc: 0.8072 - val_loss: 0.4044 - val_acc: 0.7904\n",
      "Epoch 78/500\n",
      "5062/5062 [==============================] - 0s 58us/sample - loss: 0.3992 - acc: 0.8119 - val_loss: 0.4040 - val_acc: 0.7993\n",
      "Epoch 79/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4020 - acc: 0.8121 - val_loss: 0.4017 - val_acc: 0.7940\n",
      "Epoch 80/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4010 - acc: 0.8143 - val_loss: 0.4047 - val_acc: 0.7993\n",
      "Epoch 81/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.3992 - acc: 0.8086 - val_loss: 0.4028 - val_acc: 0.7922\n",
      "Epoch 82/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4008 - acc: 0.8133 - val_loss: 0.4057 - val_acc: 0.7993\n",
      "Epoch 83/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4021 - acc: 0.8135 - val_loss: 0.4097 - val_acc: 0.7922\n",
      "Epoch 84/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4047 - acc: 0.8078 - val_loss: 0.4039 - val_acc: 0.8028\n",
      "Epoch 85/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4111 - acc: 0.8038 - val_loss: 0.4049 - val_acc: 0.7940\n",
      "Epoch 86/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4061 - acc: 0.8121 - val_loss: 0.4078 - val_acc: 0.7886\n",
      "Epoch 87/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.3999 - acc: 0.8121 - val_loss: 0.4077 - val_acc: 0.7922\n",
      "Epoch 88/500\n",
      "5062/5062 [==============================] - 0s 58us/sample - loss: 0.3979 - acc: 0.8125 - val_loss: 0.4058 - val_acc: 0.7922\n",
      "Epoch 89/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.3993 - acc: 0.8139 - val_loss: 0.4055 - val_acc: 0.7975\n",
      "Epoch 90/500\n",
      "5062/5062 [==============================] - 0s 65us/sample - loss: 0.4009 - acc: 0.8113 - val_loss: 0.4044 - val_acc: 0.7940\n",
      "Epoch 91/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.4025 - acc: 0.8141 - val_loss: 0.4062 - val_acc: 0.7922\n",
      "Epoch 92/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4037 - acc: 0.8088 - val_loss: 0.4084 - val_acc: 0.7957\n",
      "Epoch 93/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4012 - acc: 0.8129 - val_loss: 0.4078 - val_acc: 0.7993\n",
      "Epoch 94/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4039 - acc: 0.8060 - val_loss: 0.4036 - val_acc: 0.7957\n",
      "Epoch 95/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.3977 - acc: 0.8143 - val_loss: 0.4059 - val_acc: 0.7957\n",
      "Epoch 96/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3983 - acc: 0.8109 - val_loss: 0.4120 - val_acc: 0.7975\n",
      "Epoch 97/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3986 - acc: 0.8104 - val_loss: 0.4060 - val_acc: 0.7940\n",
      "Epoch 98/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3970 - acc: 0.8133 - val_loss: 0.4032 - val_acc: 0.8046\n",
      "Epoch 99/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4000 - acc: 0.8074 - val_loss: 0.4048 - val_acc: 0.7975\n",
      "Epoch 100/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4012 - acc: 0.8117 - val_loss: 0.4088 - val_acc: 0.7957\n",
      "Epoch 101/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3993 - acc: 0.8113 - val_loss: 0.4101 - val_acc: 0.8011\n",
      "Epoch 102/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4009 - acc: 0.8092 - val_loss: 0.4066 - val_acc: 0.7922\n",
      "Epoch 103/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3966 - acc: 0.8151 - val_loss: 0.4104 - val_acc: 0.7957\n",
      "Epoch 104/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4033 - acc: 0.8111 - val_loss: 0.4056 - val_acc: 0.7993\n",
      "Epoch 105/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3989 - acc: 0.8082 - val_loss: 0.4042 - val_acc: 0.7993\n",
      "Epoch 106/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3941 - acc: 0.8167 - val_loss: 0.4037 - val_acc: 0.7993\n",
      "Epoch 107/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3931 - acc: 0.8123 - val_loss: 0.4080 - val_acc: 0.8011\n",
      "Epoch 108/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3963 - acc: 0.8064 - val_loss: 0.4095 - val_acc: 0.7957\n",
      "Epoch 109/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3993 - acc: 0.8066 - val_loss: 0.4058 - val_acc: 0.7993\n",
      "Epoch 110/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4010 - acc: 0.8066 - val_loss: 0.4044 - val_acc: 0.7904\n",
      "Epoch 111/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3992 - acc: 0.8088 - val_loss: 0.4046 - val_acc: 0.8028\n",
      "Epoch 112/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3953 - acc: 0.8137 - val_loss: 0.4058 - val_acc: 0.7993\n",
      "Epoch 113/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3937 - acc: 0.8151 - val_loss: 0.4067 - val_acc: 0.8064\n",
      "Epoch 114/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3902 - acc: 0.8165 - val_loss: 0.4022 - val_acc: 0.8011\n",
      "Epoch 115/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3967 - acc: 0.8167 - val_loss: 0.4018 - val_acc: 0.8028\n",
      "Epoch 116/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3937 - acc: 0.8157 - val_loss: 0.4099 - val_acc: 0.7975\n",
      "Epoch 117/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3938 - acc: 0.8109 - val_loss: 0.4094 - val_acc: 0.7975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3939 - acc: 0.8165 - val_loss: 0.4062 - val_acc: 0.7993\n",
      "Epoch 119/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3964 - acc: 0.8113 - val_loss: 0.4058 - val_acc: 0.7957\n",
      "Epoch 120/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3920 - acc: 0.8177 - val_loss: 0.4068 - val_acc: 0.8028\n",
      "Epoch 121/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3943 - acc: 0.8177 - val_loss: 0.4103 - val_acc: 0.7940\n",
      "Epoch 122/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3934 - acc: 0.8151 - val_loss: 0.4081 - val_acc: 0.8011\n",
      "Epoch 123/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3952 - acc: 0.8137 - val_loss: 0.4026 - val_acc: 0.7975\n",
      "Epoch 124/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3966 - acc: 0.8133 - val_loss: 0.4068 - val_acc: 0.7904\n",
      "Epoch 125/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3913 - acc: 0.8159 - val_loss: 0.4060 - val_acc: 0.7993\n",
      "Epoch 126/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3950 - acc: 0.8147 - val_loss: 0.4026 - val_acc: 0.8028\n",
      "Epoch 127/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3896 - acc: 0.8141 - val_loss: 0.4076 - val_acc: 0.7957\n",
      "Epoch 128/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3908 - acc: 0.8163 - val_loss: 0.4094 - val_acc: 0.8064\n",
      "Epoch 129/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3925 - acc: 0.8117 - val_loss: 0.4105 - val_acc: 0.7957\n",
      "Epoch 130/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3957 - acc: 0.8157 - val_loss: 0.4068 - val_acc: 0.7940\n",
      "Epoch 131/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3909 - acc: 0.8107 - val_loss: 0.4028 - val_acc: 0.8064\n",
      "Epoch 132/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3882 - acc: 0.8159 - val_loss: 0.4069 - val_acc: 0.7975\n",
      "Epoch 133/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3909 - acc: 0.8147 - val_loss: 0.4045 - val_acc: 0.8046\n",
      "Epoch 134/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3903 - acc: 0.8188 - val_loss: 0.4095 - val_acc: 0.8046\n",
      "Epoch 135/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3921 - acc: 0.8153 - val_loss: 0.4128 - val_acc: 0.8028\n",
      "Epoch 136/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3946 - acc: 0.8196 - val_loss: 0.4100 - val_acc: 0.7922\n",
      "Epoch 137/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3913 - acc: 0.8151 - val_loss: 0.4044 - val_acc: 0.8046\n",
      "Epoch 138/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3880 - acc: 0.8133 - val_loss: 0.4104 - val_acc: 0.8046\n",
      "Epoch 139/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3890 - acc: 0.8137 - val_loss: 0.4094 - val_acc: 0.8082\n",
      "Epoch 140/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3850 - acc: 0.8143 - val_loss: 0.4087 - val_acc: 0.7922\n",
      "Epoch 141/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3937 - acc: 0.8165 - val_loss: 0.4083 - val_acc: 0.7993\n",
      "Epoch 142/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3875 - acc: 0.8137 - val_loss: 0.4029 - val_acc: 0.8082\n",
      "Epoch 143/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3914 - acc: 0.8163 - val_loss: 0.4028 - val_acc: 0.8046\n",
      "Epoch 144/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3859 - acc: 0.8131 - val_loss: 0.4052 - val_acc: 0.8011\n",
      "Epoch 145/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3869 - acc: 0.8175 - val_loss: 0.4070 - val_acc: 0.7922\n",
      "Epoch 146/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3885 - acc: 0.8145 - val_loss: 0.4042 - val_acc: 0.8028\n",
      "Epoch 147/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3840 - acc: 0.8206 - val_loss: 0.4098 - val_acc: 0.7904\n",
      "Epoch 148/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3924 - acc: 0.8153 - val_loss: 0.4061 - val_acc: 0.8082\n",
      "Epoch 149/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3834 - acc: 0.8186 - val_loss: 0.4125 - val_acc: 0.7993\n",
      "Epoch 150/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3828 - acc: 0.8200 - val_loss: 0.4090 - val_acc: 0.8028\n",
      "Epoch 151/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3840 - acc: 0.8200 - val_loss: 0.4057 - val_acc: 0.8099\n",
      "Epoch 152/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3826 - acc: 0.8230 - val_loss: 0.4074 - val_acc: 0.7993\n",
      "Epoch 153/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3845 - acc: 0.8196 - val_loss: 0.4081 - val_acc: 0.7957\n",
      "Epoch 154/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3851 - acc: 0.8210 - val_loss: 0.4056 - val_acc: 0.7993\n",
      "Epoch 155/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3812 - acc: 0.8230 - val_loss: 0.4134 - val_acc: 0.7993\n",
      "Epoch 156/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3916 - acc: 0.8171 - val_loss: 0.4063 - val_acc: 0.8011\n",
      "Epoch 157/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3863 - acc: 0.8157 - val_loss: 0.4038 - val_acc: 0.8011\n",
      "Epoch 158/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3849 - acc: 0.8163 - val_loss: 0.4098 - val_acc: 0.8117\n",
      "Epoch 159/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3816 - acc: 0.8232 - val_loss: 0.4118 - val_acc: 0.7922\n",
      "Epoch 160/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3826 - acc: 0.8143 - val_loss: 0.4140 - val_acc: 0.8011\n",
      "Epoch 161/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3843 - acc: 0.8163 - val_loss: 0.4081 - val_acc: 0.7993\n",
      "Epoch 162/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3850 - acc: 0.8159 - val_loss: 0.4119 - val_acc: 0.7957\n",
      "Epoch 163/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3871 - acc: 0.8125 - val_loss: 0.4089 - val_acc: 0.8011\n",
      "Epoch 164/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3895 - acc: 0.8163 - val_loss: 0.4138 - val_acc: 0.7922\n",
      "Epoch 165/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3807 - acc: 0.8179 - val_loss: 0.4117 - val_acc: 0.8046\n",
      "Epoch 166/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3850 - acc: 0.8248 - val_loss: 0.4087 - val_acc: 0.8064\n",
      "Epoch 167/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3868 - acc: 0.8151 - val_loss: 0.4079 - val_acc: 0.8028\n",
      "Epoch 168/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3830 - acc: 0.8230 - val_loss: 0.4112 - val_acc: 0.7975\n",
      "Epoch 169/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3848 - acc: 0.8169 - val_loss: 0.4097 - val_acc: 0.7904\n",
      "Epoch 170/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3855 - acc: 0.8173 - val_loss: 0.4090 - val_acc: 0.8046\n",
      "Epoch 171/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3817 - acc: 0.8232 - val_loss: 0.4075 - val_acc: 0.7975\n",
      "Epoch 172/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3836 - acc: 0.8202 - val_loss: 0.4052 - val_acc: 0.8046\n",
      "Epoch 173/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3806 - acc: 0.8208 - val_loss: 0.4035 - val_acc: 0.7993\n",
      "Epoch 174/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3809 - acc: 0.8206 - val_loss: 0.4073 - val_acc: 0.8099\n",
      "Epoch 175/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3793 - acc: 0.8175 - val_loss: 0.4092 - val_acc: 0.8028\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3823 - acc: 0.8151 - val_loss: 0.4073 - val_acc: 0.7993\n",
      "Epoch 177/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3815 - acc: 0.8212 - val_loss: 0.4074 - val_acc: 0.8064\n",
      "Epoch 178/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3854 - acc: 0.8137 - val_loss: 0.4054 - val_acc: 0.7975\n",
      "Epoch 179/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3813 - acc: 0.8226 - val_loss: 0.4046 - val_acc: 0.7940\n",
      "Epoch 180/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3823 - acc: 0.8194 - val_loss: 0.4068 - val_acc: 0.7957\n",
      "Epoch 181/500\n",
      "5062/5062 [==============================] - 0s 69us/sample - loss: 0.3797 - acc: 0.8151 - val_loss: 0.4045 - val_acc: 0.8028\n",
      "Epoch 182/500\n",
      "5062/5062 [==============================] - 0s 59us/sample - loss: 0.3814 - acc: 0.8179 - val_loss: 0.4071 - val_acc: 0.8028\n",
      "Epoch 183/500\n",
      "5062/5062 [==============================] - 0s 65us/sample - loss: 0.3786 - acc: 0.8198 - val_loss: 0.4048 - val_acc: 0.8046\n",
      "Epoch 184/500\n",
      "5062/5062 [==============================] - 0s 59us/sample - loss: 0.3737 - acc: 0.8252 - val_loss: 0.4060 - val_acc: 0.8064\n",
      "Epoch 185/500\n",
      "5062/5062 [==============================] - 0s 64us/sample - loss: 0.3883 - acc: 0.8159 - val_loss: 0.4021 - val_acc: 0.8011\n",
      "Epoch 186/500\n",
      "5062/5062 [==============================] - 0s 63us/sample - loss: 0.3816 - acc: 0.8171 - val_loss: 0.4072 - val_acc: 0.8011\n",
      "Epoch 187/500\n",
      "5062/5062 [==============================] - 0s 67us/sample - loss: 0.3775 - acc: 0.8167 - val_loss: 0.4086 - val_acc: 0.7993\n",
      "Epoch 188/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.3758 - acc: 0.8210 - val_loss: 0.4150 - val_acc: 0.7957\n",
      "Epoch 189/500\n",
      "5062/5062 [==============================] - 0s 64us/sample - loss: 0.3814 - acc: 0.8163 - val_loss: 0.4049 - val_acc: 0.8082\n",
      "Epoch 190/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3805 - acc: 0.8212 - val_loss: 0.4105 - val_acc: 0.8028\n",
      "Epoch 191/500\n",
      "5062/5062 [==============================] - 0s 73us/sample - loss: 0.3812 - acc: 0.8236 - val_loss: 0.4054 - val_acc: 0.8028\n",
      "Epoch 192/500\n",
      "5062/5062 [==============================] - 0s 65us/sample - loss: 0.3795 - acc: 0.8238 - val_loss: 0.4106 - val_acc: 0.8011\n",
      "Epoch 193/500\n",
      "5062/5062 [==============================] - 0s 64us/sample - loss: 0.3763 - acc: 0.8224 - val_loss: 0.4122 - val_acc: 0.7940\n",
      "Epoch 194/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.3784 - acc: 0.8188 - val_loss: 0.4077 - val_acc: 0.8117\n",
      "Epoch 195/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.3793 - acc: 0.8173 - val_loss: 0.4127 - val_acc: 0.8028\n",
      "Epoch 196/500\n",
      "5062/5062 [==============================] - 0s 64us/sample - loss: 0.3790 - acc: 0.8200 - val_loss: 0.4098 - val_acc: 0.7993\n",
      "Epoch 197/500\n",
      "5062/5062 [==============================] - 0s 66us/sample - loss: 0.3725 - acc: 0.8190 - val_loss: 0.4055 - val_acc: 0.8028\n",
      "Epoch 198/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.3777 - acc: 0.8181 - val_loss: 0.4122 - val_acc: 0.8011\n",
      "Epoch 199/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3811 - acc: 0.8240 - val_loss: 0.4080 - val_acc: 0.7993\n",
      "Epoch 200/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3736 - acc: 0.8285 - val_loss: 0.4135 - val_acc: 0.8028\n",
      "Epoch 201/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3749 - acc: 0.8210 - val_loss: 0.4126 - val_acc: 0.8011\n",
      "Epoch 202/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3749 - acc: 0.8262 - val_loss: 0.4110 - val_acc: 0.8028\n",
      "Epoch 203/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3749 - acc: 0.8264 - val_loss: 0.4102 - val_acc: 0.7993\n",
      "Epoch 204/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3778 - acc: 0.8230 - val_loss: 0.4082 - val_acc: 0.7975\n",
      "Epoch 205/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3787 - acc: 0.8188 - val_loss: 0.4135 - val_acc: 0.8011\n",
      "Epoch 206/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3755 - acc: 0.8208 - val_loss: 0.4101 - val_acc: 0.8082\n",
      "Epoch 207/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3704 - acc: 0.8236 - val_loss: 0.4114 - val_acc: 0.8028\n",
      "Epoch 208/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3728 - acc: 0.8183 - val_loss: 0.4109 - val_acc: 0.7957\n",
      "Epoch 209/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3739 - acc: 0.8228 - val_loss: 0.4064 - val_acc: 0.8046\n",
      "Epoch 210/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3748 - acc: 0.8240 - val_loss: 0.4098 - val_acc: 0.8082\n",
      "Epoch 211/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3708 - acc: 0.8267 - val_loss: 0.4112 - val_acc: 0.8064\n",
      "Epoch 212/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3752 - acc: 0.8287 - val_loss: 0.4086 - val_acc: 0.8099\n",
      "Epoch 213/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3687 - acc: 0.8234 - val_loss: 0.4058 - val_acc: 0.8064\n",
      "Epoch 214/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3728 - acc: 0.8232 - val_loss: 0.4142 - val_acc: 0.8011\n",
      "Epoch 215/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3761 - acc: 0.8218 - val_loss: 0.4103 - val_acc: 0.8028\n",
      "Epoch 216/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3746 - acc: 0.8236 - val_loss: 0.4090 - val_acc: 0.8117\n",
      "Epoch 217/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3742 - acc: 0.8267 - val_loss: 0.4083 - val_acc: 0.8011\n",
      "Epoch 218/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3711 - acc: 0.8285 - val_loss: 0.4142 - val_acc: 0.7922\n",
      "Epoch 219/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3640 - acc: 0.8301 - val_loss: 0.4220 - val_acc: 0.7975\n",
      "Epoch 220/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3722 - acc: 0.8266 - val_loss: 0.4210 - val_acc: 0.7922\n",
      "Epoch 221/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3706 - acc: 0.8327 - val_loss: 0.4152 - val_acc: 0.7993\n",
      "Epoch 222/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3754 - acc: 0.8234 - val_loss: 0.4102 - val_acc: 0.8046\n",
      "Epoch 223/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3710 - acc: 0.8236 - val_loss: 0.4096 - val_acc: 0.8046\n",
      "Epoch 224/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3756 - acc: 0.8218 - val_loss: 0.4072 - val_acc: 0.8064\n",
      "Epoch 225/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3737 - acc: 0.8234 - val_loss: 0.4102 - val_acc: 0.8064\n",
      "Epoch 226/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3693 - acc: 0.8279 - val_loss: 0.4158 - val_acc: 0.7940\n",
      "Epoch 227/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3733 - acc: 0.8297 - val_loss: 0.4117 - val_acc: 0.8011\n",
      "Epoch 228/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3713 - acc: 0.8297 - val_loss: 0.4210 - val_acc: 0.7940\n",
      "Epoch 229/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3644 - acc: 0.8301 - val_loss: 0.4246 - val_acc: 0.7922\n",
      "Epoch 230/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3660 - acc: 0.8293 - val_loss: 0.4209 - val_acc: 0.7940\n",
      "Epoch 231/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3708 - acc: 0.8281 - val_loss: 0.4136 - val_acc: 0.8028\n",
      "Epoch 232/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3699 - acc: 0.8246 - val_loss: 0.4117 - val_acc: 0.7957\n",
      "Epoch 233/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3720 - acc: 0.8238 - val_loss: 0.4144 - val_acc: 0.7975\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.3656 - acc: 0.8287 - val_loss: 0.4247 - val_acc: 0.8028\n",
      "Epoch 235/500\n",
      "5062/5062 [==============================] - 0s 62us/sample - loss: 0.3706 - acc: 0.8226 - val_loss: 0.4127 - val_acc: 0.8064\n",
      "Epoch 236/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3695 - acc: 0.8226 - val_loss: 0.4094 - val_acc: 0.8046\n",
      "Epoch 237/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3701 - acc: 0.8267 - val_loss: 0.4104 - val_acc: 0.8117\n",
      "Epoch 238/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3711 - acc: 0.8230 - val_loss: 0.4104 - val_acc: 0.7957\n",
      "Epoch 239/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3727 - acc: 0.8216 - val_loss: 0.4095 - val_acc: 0.8153\n",
      "Epoch 240/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3681 - acc: 0.8246 - val_loss: 0.4205 - val_acc: 0.7957\n",
      "Epoch 241/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3681 - acc: 0.8260 - val_loss: 0.4125 - val_acc: 0.8082\n",
      "Epoch 242/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3650 - acc: 0.8285 - val_loss: 0.4171 - val_acc: 0.8064\n",
      "Epoch 243/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3662 - acc: 0.8254 - val_loss: 0.4199 - val_acc: 0.8064\n",
      "Epoch 244/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3642 - acc: 0.8313 - val_loss: 0.4061 - val_acc: 0.8011\n",
      "Epoch 245/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3679 - acc: 0.8269 - val_loss: 0.4132 - val_acc: 0.8046\n",
      "Epoch 246/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3655 - acc: 0.8289 - val_loss: 0.4190 - val_acc: 0.8046\n",
      "Epoch 247/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3664 - acc: 0.8309 - val_loss: 0.4130 - val_acc: 0.8011\n",
      "Epoch 248/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3696 - acc: 0.8267 - val_loss: 0.4201 - val_acc: 0.7922\n",
      "Epoch 249/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3672 - acc: 0.8246 - val_loss: 0.4130 - val_acc: 0.8046\n",
      "Epoch 250/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3656 - acc: 0.8321 - val_loss: 0.4152 - val_acc: 0.8046\n",
      "Epoch 251/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3697 - acc: 0.8220 - val_loss: 0.4188 - val_acc: 0.7993\n",
      "Epoch 252/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3678 - acc: 0.8240 - val_loss: 0.4243 - val_acc: 0.7957\n",
      "Epoch 253/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3666 - acc: 0.8244 - val_loss: 0.4138 - val_acc: 0.7957\n",
      "Epoch 254/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3728 - acc: 0.8236 - val_loss: 0.4156 - val_acc: 0.8011\n",
      "Epoch 255/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3637 - acc: 0.8291 - val_loss: 0.4133 - val_acc: 0.7957\n",
      "Epoch 256/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3623 - acc: 0.8291 - val_loss: 0.4129 - val_acc: 0.8064\n",
      "Epoch 257/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3681 - acc: 0.8299 - val_loss: 0.4167 - val_acc: 0.8046\n",
      "Epoch 258/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3679 - acc: 0.8311 - val_loss: 0.4150 - val_acc: 0.7993\n",
      "Epoch 259/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3622 - acc: 0.8285 - val_loss: 0.4256 - val_acc: 0.7815\n",
      "Epoch 260/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3623 - acc: 0.8319 - val_loss: 0.4135 - val_acc: 0.7957\n",
      "Epoch 261/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3613 - acc: 0.8273 - val_loss: 0.4134 - val_acc: 0.8028\n",
      "Epoch 262/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3638 - acc: 0.8283 - val_loss: 0.4161 - val_acc: 0.7940\n",
      "Epoch 263/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3615 - acc: 0.8291 - val_loss: 0.4204 - val_acc: 0.7993\n",
      "Epoch 264/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3646 - acc: 0.8250 - val_loss: 0.4195 - val_acc: 0.7957\n",
      "Epoch 265/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3657 - acc: 0.8242 - val_loss: 0.4189 - val_acc: 0.8046\n",
      "Epoch 266/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3618 - acc: 0.8331 - val_loss: 0.4194 - val_acc: 0.7993\n",
      "Epoch 267/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3655 - acc: 0.8337 - val_loss: 0.4212 - val_acc: 0.8046\n",
      "Epoch 268/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3623 - acc: 0.8341 - val_loss: 0.4204 - val_acc: 0.7940\n",
      "Epoch 269/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3696 - acc: 0.8260 - val_loss: 0.4239 - val_acc: 0.8011\n",
      "Epoch 270/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3669 - acc: 0.8222 - val_loss: 0.4193 - val_acc: 0.7851\n",
      "Epoch 271/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3660 - acc: 0.8260 - val_loss: 0.4195 - val_acc: 0.7993\n",
      "Epoch 272/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3685 - acc: 0.8266 - val_loss: 0.4215 - val_acc: 0.7957\n",
      "Epoch 273/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3693 - acc: 0.8250 - val_loss: 0.4190 - val_acc: 0.8082\n",
      "Epoch 274/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3629 - acc: 0.8264 - val_loss: 0.4178 - val_acc: 0.7993\n",
      "Epoch 275/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3672 - acc: 0.8248 - val_loss: 0.4191 - val_acc: 0.7993\n",
      "Epoch 276/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3585 - acc: 0.8323 - val_loss: 0.4163 - val_acc: 0.7993\n",
      "Epoch 277/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3655 - acc: 0.8295 - val_loss: 0.4233 - val_acc: 0.8099\n",
      "Epoch 278/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3623 - acc: 0.8323 - val_loss: 0.4214 - val_acc: 0.7957\n",
      "Epoch 279/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3662 - acc: 0.8246 - val_loss: 0.4186 - val_acc: 0.7975\n",
      "Epoch 280/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3612 - acc: 0.8301 - val_loss: 0.4251 - val_acc: 0.7957\n",
      "Epoch 281/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3634 - acc: 0.8317 - val_loss: 0.4212 - val_acc: 0.7957\n",
      "Epoch 282/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3627 - acc: 0.8317 - val_loss: 0.4147 - val_acc: 0.8011\n",
      "Epoch 283/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3626 - acc: 0.8305 - val_loss: 0.4183 - val_acc: 0.8028\n",
      "Epoch 284/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3617 - acc: 0.8301 - val_loss: 0.4173 - val_acc: 0.8135\n",
      "Epoch 285/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3567 - acc: 0.8341 - val_loss: 0.4257 - val_acc: 0.8064\n",
      "Epoch 286/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3575 - acc: 0.8303 - val_loss: 0.4239 - val_acc: 0.8011\n",
      "Epoch 287/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3563 - acc: 0.8331 - val_loss: 0.4144 - val_acc: 0.8117\n",
      "Epoch 288/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3574 - acc: 0.8356 - val_loss: 0.4186 - val_acc: 0.7975\n",
      "Epoch 289/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3537 - acc: 0.8348 - val_loss: 0.4273 - val_acc: 0.8082\n",
      "Epoch 290/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3578 - acc: 0.8301 - val_loss: 0.4282 - val_acc: 0.7957\n",
      "Epoch 291/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3522 - acc: 0.8323 - val_loss: 0.4266 - val_acc: 0.7922\n",
      "Epoch 292/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3514 - acc: 0.8317 - val_loss: 0.4283 - val_acc: 0.8064\n",
      "Epoch 293/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3551 - acc: 0.8343 - val_loss: 0.4252 - val_acc: 0.8082\n",
      "Epoch 294/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3594 - acc: 0.8333 - val_loss: 0.4196 - val_acc: 0.8064\n",
      "Epoch 295/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3552 - acc: 0.8345 - val_loss: 0.4273 - val_acc: 0.8082\n",
      "Epoch 296/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3584 - acc: 0.8345 - val_loss: 0.4299 - val_acc: 0.7975\n",
      "Epoch 297/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3506 - acc: 0.8360 - val_loss: 0.4295 - val_acc: 0.7957\n",
      "Epoch 298/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3542 - acc: 0.8345 - val_loss: 0.4299 - val_acc: 0.8082\n",
      "Epoch 299/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3458 - acc: 0.8404 - val_loss: 0.4279 - val_acc: 0.8011\n",
      "Epoch 300/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3575 - acc: 0.8339 - val_loss: 0.4328 - val_acc: 0.8064\n",
      "Epoch 301/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3517 - acc: 0.8418 - val_loss: 0.4400 - val_acc: 0.8028\n",
      "Epoch 302/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3556 - acc: 0.8297 - val_loss: 0.4308 - val_acc: 0.8135\n",
      "Epoch 303/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3513 - acc: 0.8331 - val_loss: 0.4332 - val_acc: 0.8011\n",
      "Epoch 304/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3553 - acc: 0.8305 - val_loss: 0.4296 - val_acc: 0.8046\n",
      "Epoch 305/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3548 - acc: 0.8315 - val_loss: 0.4322 - val_acc: 0.7922\n",
      "Epoch 306/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3489 - acc: 0.8325 - val_loss: 0.4400 - val_acc: 0.7993\n",
      "Epoch 307/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3575 - acc: 0.8321 - val_loss: 0.4314 - val_acc: 0.7940\n",
      "Epoch 308/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3544 - acc: 0.8281 - val_loss: 0.4338 - val_acc: 0.7940\n",
      "Epoch 309/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3620 - acc: 0.8323 - val_loss: 0.4278 - val_acc: 0.7957\n",
      "Epoch 310/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3498 - acc: 0.8362 - val_loss: 0.4473 - val_acc: 0.7975\n",
      "Epoch 311/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3593 - acc: 0.8293 - val_loss: 0.4330 - val_acc: 0.8028\n",
      "Epoch 312/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3535 - acc: 0.8327 - val_loss: 0.4331 - val_acc: 0.7922\n",
      "Epoch 313/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3527 - acc: 0.8333 - val_loss: 0.4407 - val_acc: 0.7975\n",
      "Epoch 314/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3586 - acc: 0.8277 - val_loss: 0.4224 - val_acc: 0.7957\n",
      "Epoch 315/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3564 - acc: 0.8301 - val_loss: 0.4321 - val_acc: 0.7957\n",
      "Epoch 316/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3553 - acc: 0.8362 - val_loss: 0.4337 - val_acc: 0.7975\n",
      "Epoch 317/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.3501 - acc: 0.8339 - val_loss: 0.4275 - val_acc: 0.7957\n",
      "Epoch 318/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3544 - acc: 0.8317 - val_loss: 0.4411 - val_acc: 0.7993\n",
      "Epoch 319/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3586 - acc: 0.8339 - val_loss: 0.4296 - val_acc: 0.7975\n",
      "Epoch 320/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.3537 - acc: 0.8337 - val_loss: 0.4320 - val_acc: 0.8011\n",
      "Epoch 321/500\n",
      "5062/5062 [==============================] - 0s 64us/sample - loss: 0.3551 - acc: 0.8277 - val_loss: 0.4257 - val_acc: 0.7957\n",
      "Epoch 322/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3467 - acc: 0.8384 - val_loss: 0.4363 - val_acc: 0.7975\n",
      "Epoch 323/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3505 - acc: 0.8394 - val_loss: 0.4278 - val_acc: 0.7957\n",
      "Epoch 324/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3425 - acc: 0.8412 - val_loss: 0.4303 - val_acc: 0.7940\n",
      "Epoch 325/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.3467 - acc: 0.8384 - val_loss: 0.4357 - val_acc: 0.7869\n",
      "Epoch 326/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3568 - acc: 0.8329 - val_loss: 0.4305 - val_acc: 0.7798\n",
      "Epoch 327/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3516 - acc: 0.8358 - val_loss: 0.4273 - val_acc: 0.7851\n",
      "Epoch 328/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3469 - acc: 0.8386 - val_loss: 0.4294 - val_acc: 0.7922\n",
      "Epoch 329/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3518 - acc: 0.8331 - val_loss: 0.4331 - val_acc: 0.7886\n",
      "Epoch 330/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3538 - acc: 0.8337 - val_loss: 0.4253 - val_acc: 0.7886\n",
      "Epoch 331/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.3502 - acc: 0.8352 - val_loss: 0.4348 - val_acc: 0.8011\n",
      "Epoch 332/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3532 - acc: 0.8339 - val_loss: 0.4432 - val_acc: 0.7904\n",
      "Epoch 333/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3492 - acc: 0.8394 - val_loss: 0.4301 - val_acc: 0.7940\n",
      "Epoch 334/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3482 - acc: 0.8386 - val_loss: 0.4380 - val_acc: 0.7904\n",
      "Epoch 335/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3513 - acc: 0.8370 - val_loss: 0.4375 - val_acc: 0.7922\n",
      "Epoch 336/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3511 - acc: 0.8341 - val_loss: 0.4392 - val_acc: 0.7886\n",
      "Epoch 337/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3503 - acc: 0.8370 - val_loss: 0.4352 - val_acc: 0.7833\n",
      "Epoch 338/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3459 - acc: 0.8352 - val_loss: 0.4374 - val_acc: 0.7833\n",
      "Epoch 339/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3525 - acc: 0.8368 - val_loss: 0.4430 - val_acc: 0.7904\n",
      "Epoch 340/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3471 - acc: 0.8307 - val_loss: 0.4348 - val_acc: 0.7833\n",
      "Epoch 341/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3461 - acc: 0.8378 - val_loss: 0.4404 - val_acc: 0.7780\n",
      "Epoch 342/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3408 - acc: 0.8362 - val_loss: 0.4425 - val_acc: 0.7940\n",
      "Epoch 343/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3461 - acc: 0.8331 - val_loss: 0.4457 - val_acc: 0.7886\n",
      "Epoch 344/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3432 - acc: 0.8394 - val_loss: 0.4423 - val_acc: 0.7886\n",
      "Epoch 345/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3410 - acc: 0.8406 - val_loss: 0.4361 - val_acc: 0.7940\n",
      "Epoch 346/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3498 - acc: 0.8331 - val_loss: 0.4444 - val_acc: 0.7957\n",
      "Epoch 347/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3445 - acc: 0.8402 - val_loss: 0.4334 - val_acc: 0.8028\n",
      "Epoch 348/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3447 - acc: 0.8406 - val_loss: 0.4308 - val_acc: 0.8028\n",
      "Epoch 349/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3485 - acc: 0.8319 - val_loss: 0.4297 - val_acc: 0.7886\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3497 - acc: 0.8289 - val_loss: 0.4317 - val_acc: 0.7957\n",
      "Epoch 351/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3487 - acc: 0.8343 - val_loss: 0.4362 - val_acc: 0.7940\n",
      "Epoch 352/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3484 - acc: 0.8360 - val_loss: 0.4343 - val_acc: 0.7957\n",
      "Epoch 353/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3443 - acc: 0.8348 - val_loss: 0.4341 - val_acc: 0.7886\n",
      "Epoch 354/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3390 - acc: 0.8412 - val_loss: 0.4466 - val_acc: 0.7975\n",
      "Epoch 355/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3503 - acc: 0.8406 - val_loss: 0.4264 - val_acc: 0.7993\n",
      "Epoch 356/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3441 - acc: 0.8404 - val_loss: 0.4277 - val_acc: 0.8028\n",
      "Epoch 357/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3465 - acc: 0.8368 - val_loss: 0.4393 - val_acc: 0.8011\n",
      "Epoch 358/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3365 - acc: 0.8404 - val_loss: 0.4370 - val_acc: 0.7975\n",
      "Epoch 359/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3499 - acc: 0.8341 - val_loss: 0.4467 - val_acc: 0.7922\n",
      "Epoch 360/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3438 - acc: 0.8402 - val_loss: 0.4329 - val_acc: 0.7904\n",
      "Epoch 361/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3364 - acc: 0.8451 - val_loss: 0.4408 - val_acc: 0.7957\n",
      "Epoch 362/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3440 - acc: 0.8412 - val_loss: 0.4414 - val_acc: 0.7886\n",
      "Epoch 363/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3407 - acc: 0.8390 - val_loss: 0.4438 - val_acc: 0.7904\n",
      "Epoch 364/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3336 - acc: 0.8406 - val_loss: 0.4529 - val_acc: 0.7886\n",
      "Epoch 365/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3461 - acc: 0.8400 - val_loss: 0.4381 - val_acc: 0.7993\n",
      "Epoch 366/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3421 - acc: 0.8384 - val_loss: 0.4319 - val_acc: 0.7957\n",
      "Epoch 367/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3407 - acc: 0.8441 - val_loss: 0.4331 - val_acc: 0.7922\n",
      "Epoch 368/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3438 - acc: 0.8427 - val_loss: 0.4475 - val_acc: 0.7993\n",
      "Epoch 369/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3440 - acc: 0.8426 - val_loss: 0.4344 - val_acc: 0.7975\n",
      "Epoch 370/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3333 - acc: 0.8451 - val_loss: 0.4434 - val_acc: 0.7957\n",
      "Epoch 371/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3357 - acc: 0.8402 - val_loss: 0.4407 - val_acc: 0.8011\n",
      "Epoch 372/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3337 - acc: 0.8437 - val_loss: 0.4435 - val_acc: 0.8028\n",
      "Epoch 373/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3446 - acc: 0.8390 - val_loss: 0.4260 - val_acc: 0.8028\n",
      "Epoch 374/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3446 - acc: 0.8372 - val_loss: 0.4364 - val_acc: 0.7957\n",
      "Epoch 375/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3383 - acc: 0.8380 - val_loss: 0.4396 - val_acc: 0.7957\n",
      "Epoch 376/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3412 - acc: 0.8374 - val_loss: 0.4410 - val_acc: 0.7957\n",
      "Epoch 377/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3435 - acc: 0.8406 - val_loss: 0.4356 - val_acc: 0.7904\n",
      "Epoch 378/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3357 - acc: 0.8418 - val_loss: 0.4412 - val_acc: 0.7993\n",
      "Epoch 379/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3384 - acc: 0.8433 - val_loss: 0.4493 - val_acc: 0.7922\n",
      "Epoch 380/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3403 - acc: 0.8412 - val_loss: 0.4365 - val_acc: 0.7940\n",
      "Epoch 381/500\n",
      "5062/5062 [==============================] - 0s 46us/sample - loss: 0.3365 - acc: 0.8424 - val_loss: 0.4410 - val_acc: 0.8011\n",
      "Epoch 382/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3406 - acc: 0.8449 - val_loss: 0.4450 - val_acc: 0.7975\n",
      "Epoch 383/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3386 - acc: 0.8457 - val_loss: 0.4355 - val_acc: 0.7940\n",
      "Epoch 384/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3374 - acc: 0.8378 - val_loss: 0.4409 - val_acc: 0.7922\n",
      "Epoch 385/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3346 - acc: 0.8451 - val_loss: 0.4408 - val_acc: 0.7851\n",
      "Epoch 386/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3333 - acc: 0.8433 - val_loss: 0.4482 - val_acc: 0.8011\n",
      "Epoch 387/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3345 - acc: 0.8424 - val_loss: 0.4387 - val_acc: 0.7957\n",
      "Epoch 388/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3335 - acc: 0.8408 - val_loss: 0.4460 - val_acc: 0.7940\n",
      "Epoch 389/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3340 - acc: 0.8412 - val_loss: 0.4473 - val_acc: 0.8011\n",
      "Epoch 390/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3388 - acc: 0.8437 - val_loss: 0.4493 - val_acc: 0.7940\n",
      "Epoch 391/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3350 - acc: 0.8445 - val_loss: 0.4383 - val_acc: 0.7975\n",
      "Epoch 392/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3312 - acc: 0.8427 - val_loss: 0.4519 - val_acc: 0.7975\n",
      "Epoch 393/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3369 - acc: 0.8445 - val_loss: 0.4513 - val_acc: 0.7993\n",
      "Epoch 394/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3359 - acc: 0.8439 - val_loss: 0.4496 - val_acc: 0.7957\n",
      "Epoch 395/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3367 - acc: 0.8435 - val_loss: 0.4425 - val_acc: 0.7904\n",
      "Epoch 396/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3353 - acc: 0.8449 - val_loss: 0.4476 - val_acc: 0.7957\n",
      "Epoch 397/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3396 - acc: 0.8420 - val_loss: 0.4438 - val_acc: 0.7993\n",
      "Epoch 398/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3333 - acc: 0.8433 - val_loss: 0.4482 - val_acc: 0.7922\n",
      "Epoch 399/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3358 - acc: 0.8408 - val_loss: 0.4539 - val_acc: 0.7869\n",
      "Epoch 400/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3350 - acc: 0.8374 - val_loss: 0.4516 - val_acc: 0.7869\n",
      "Epoch 401/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3385 - acc: 0.8382 - val_loss: 0.4547 - val_acc: 0.7798\n",
      "Epoch 402/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3295 - acc: 0.8487 - val_loss: 0.4509 - val_acc: 0.7904\n",
      "Epoch 403/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3380 - acc: 0.8386 - val_loss: 0.4441 - val_acc: 0.7975\n",
      "Epoch 404/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3333 - acc: 0.8433 - val_loss: 0.4537 - val_acc: 0.7957\n",
      "Epoch 405/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3337 - acc: 0.8457 - val_loss: 0.4524 - val_acc: 0.7815\n",
      "Epoch 406/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3343 - acc: 0.8431 - val_loss: 0.4542 - val_acc: 0.7940\n",
      "Epoch 407/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3344 - acc: 0.8376 - val_loss: 0.4436 - val_acc: 0.7922\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3383 - acc: 0.8400 - val_loss: 0.4561 - val_acc: 0.7904\n",
      "Epoch 409/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3364 - acc: 0.8398 - val_loss: 0.4375 - val_acc: 0.7904\n",
      "Epoch 410/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3293 - acc: 0.8449 - val_loss: 0.4517 - val_acc: 0.7815\n",
      "Epoch 411/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3295 - acc: 0.8497 - val_loss: 0.4398 - val_acc: 0.7993\n",
      "Epoch 412/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3266 - acc: 0.8495 - val_loss: 0.4539 - val_acc: 0.7940\n",
      "Epoch 413/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3260 - acc: 0.8483 - val_loss: 0.4545 - val_acc: 0.7993\n",
      "Epoch 414/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3302 - acc: 0.8459 - val_loss: 0.4528 - val_acc: 0.7904\n",
      "Epoch 415/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3344 - acc: 0.8386 - val_loss: 0.4450 - val_acc: 0.8028\n",
      "Epoch 416/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3395 - acc: 0.8463 - val_loss: 0.4361 - val_acc: 0.8028\n",
      "Epoch 417/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3259 - acc: 0.8481 - val_loss: 0.4491 - val_acc: 0.7922\n",
      "Epoch 418/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3303 - acc: 0.8459 - val_loss: 0.4488 - val_acc: 0.7922\n",
      "Epoch 419/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3257 - acc: 0.8508 - val_loss: 0.4501 - val_acc: 0.7940\n",
      "Epoch 420/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3385 - acc: 0.8408 - val_loss: 0.4506 - val_acc: 0.7975\n",
      "Epoch 421/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3311 - acc: 0.8422 - val_loss: 0.4592 - val_acc: 0.7940\n",
      "Epoch 422/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3295 - acc: 0.8437 - val_loss: 0.4600 - val_acc: 0.7957\n",
      "Epoch 423/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3355 - acc: 0.8402 - val_loss: 0.4466 - val_acc: 0.7940\n",
      "Epoch 424/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3382 - acc: 0.8414 - val_loss: 0.4490 - val_acc: 0.8011\n",
      "Epoch 425/500\n",
      "5062/5062 [==============================] - 0s 65us/sample - loss: 0.3274 - acc: 0.8426 - val_loss: 0.4507 - val_acc: 0.7851\n",
      "Epoch 426/500\n",
      "5062/5062 [==============================] - 0s 76us/sample - loss: 0.3428 - acc: 0.8386 - val_loss: 0.4468 - val_acc: 0.7957\n",
      "Epoch 427/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3292 - acc: 0.8461 - val_loss: 0.4407 - val_acc: 0.7957\n",
      "Epoch 428/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3325 - acc: 0.8447 - val_loss: 0.4578 - val_acc: 0.7957\n",
      "Epoch 429/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3264 - acc: 0.8457 - val_loss: 0.4496 - val_acc: 0.7940\n",
      "Epoch 430/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3315 - acc: 0.8429 - val_loss: 0.4584 - val_acc: 0.7975\n",
      "Epoch 431/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3216 - acc: 0.8528 - val_loss: 0.4673 - val_acc: 0.7940\n",
      "Epoch 432/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3281 - acc: 0.8433 - val_loss: 0.4565 - val_acc: 0.7904\n",
      "Epoch 433/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3273 - acc: 0.8493 - val_loss: 0.4597 - val_acc: 0.7922\n",
      "Epoch 434/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3260 - acc: 0.8459 - val_loss: 0.4543 - val_acc: 0.7922\n",
      "Epoch 435/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3267 - acc: 0.8491 - val_loss: 0.4593 - val_acc: 0.7975\n",
      "Epoch 436/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3232 - acc: 0.8508 - val_loss: 0.4699 - val_acc: 0.7975\n",
      "Epoch 437/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3331 - acc: 0.8429 - val_loss: 0.4542 - val_acc: 0.7975\n",
      "Epoch 438/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3322 - acc: 0.8439 - val_loss: 0.4630 - val_acc: 0.7957\n",
      "Epoch 439/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3287 - acc: 0.8439 - val_loss: 0.4673 - val_acc: 0.7957\n",
      "Epoch 440/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3207 - acc: 0.8477 - val_loss: 0.4676 - val_acc: 0.8028\n",
      "Epoch 441/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3198 - acc: 0.8503 - val_loss: 0.4532 - val_acc: 0.8046\n",
      "Epoch 442/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3289 - acc: 0.8427 - val_loss: 0.4525 - val_acc: 0.7975\n",
      "Epoch 443/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3345 - acc: 0.8451 - val_loss: 0.4453 - val_acc: 0.8011\n",
      "Epoch 444/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3260 - acc: 0.8487 - val_loss: 0.4589 - val_acc: 0.7957\n",
      "Epoch 445/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3262 - acc: 0.8481 - val_loss: 0.4590 - val_acc: 0.7975\n",
      "Epoch 446/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3171 - acc: 0.8530 - val_loss: 0.4608 - val_acc: 0.7940\n",
      "Epoch 447/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3262 - acc: 0.8471 - val_loss: 0.4628 - val_acc: 0.7975\n",
      "Epoch 448/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3286 - acc: 0.8465 - val_loss: 0.4619 - val_acc: 0.7869\n",
      "Epoch 449/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3310 - acc: 0.8483 - val_loss: 0.4589 - val_acc: 0.8011\n",
      "Epoch 450/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3254 - acc: 0.8457 - val_loss: 0.4636 - val_acc: 0.7975\n",
      "Epoch 451/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3291 - acc: 0.8420 - val_loss: 0.4626 - val_acc: 0.7975\n",
      "Epoch 452/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3345 - acc: 0.8437 - val_loss: 0.4438 - val_acc: 0.7975\n",
      "Epoch 453/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3241 - acc: 0.8485 - val_loss: 0.4511 - val_acc: 0.7886\n",
      "Epoch 454/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3247 - acc: 0.8418 - val_loss: 0.4725 - val_acc: 0.7904\n",
      "Epoch 455/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3222 - acc: 0.8508 - val_loss: 0.4683 - val_acc: 0.7904\n",
      "Epoch 456/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3280 - acc: 0.8463 - val_loss: 0.4660 - val_acc: 0.7904\n",
      "Epoch 457/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3294 - acc: 0.8422 - val_loss: 0.4612 - val_acc: 0.8046\n",
      "Epoch 458/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3344 - acc: 0.8347 - val_loss: 0.4516 - val_acc: 0.8082\n",
      "Epoch 459/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3202 - acc: 0.8514 - val_loss: 0.4608 - val_acc: 0.8046\n",
      "Epoch 460/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3299 - acc: 0.8447 - val_loss: 0.4672 - val_acc: 0.8011\n",
      "Epoch 461/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3289 - acc: 0.8467 - val_loss: 0.4600 - val_acc: 0.7993\n",
      "Epoch 462/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3196 - acc: 0.8514 - val_loss: 0.4549 - val_acc: 0.7957\n",
      "Epoch 463/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3271 - acc: 0.8453 - val_loss: 0.4594 - val_acc: 0.8011\n",
      "Epoch 464/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3195 - acc: 0.8491 - val_loss: 0.4633 - val_acc: 0.7957\n",
      "Epoch 465/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3135 - acc: 0.8507 - val_loss: 0.4616 - val_acc: 0.7975\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3262 - acc: 0.8465 - val_loss: 0.4531 - val_acc: 0.7904\n",
      "Epoch 467/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3243 - acc: 0.8505 - val_loss: 0.4619 - val_acc: 0.7833\n",
      "Epoch 468/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3225 - acc: 0.8524 - val_loss: 0.4655 - val_acc: 0.7940\n",
      "Epoch 469/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3264 - acc: 0.8463 - val_loss: 0.4720 - val_acc: 0.7922\n",
      "Epoch 470/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3245 - acc: 0.8479 - val_loss: 0.4648 - val_acc: 0.7940\n",
      "Epoch 471/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3224 - acc: 0.8495 - val_loss: 0.4623 - val_acc: 0.7940\n",
      "Epoch 472/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3177 - acc: 0.8558 - val_loss: 0.4617 - val_acc: 0.7957\n",
      "Epoch 473/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3100 - acc: 0.8576 - val_loss: 0.4787 - val_acc: 0.7940\n",
      "Epoch 474/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3181 - acc: 0.8437 - val_loss: 0.4811 - val_acc: 0.7869\n",
      "Epoch 475/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3257 - acc: 0.8503 - val_loss: 0.4628 - val_acc: 0.7851\n",
      "Epoch 476/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3171 - acc: 0.8512 - val_loss: 0.4750 - val_acc: 0.7922\n",
      "Epoch 477/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3254 - acc: 0.8485 - val_loss: 0.4814 - val_acc: 0.7886\n",
      "Epoch 478/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3202 - acc: 0.8507 - val_loss: 0.4648 - val_acc: 0.7975\n",
      "Epoch 479/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3329 - acc: 0.8433 - val_loss: 0.4574 - val_acc: 0.7904\n",
      "Epoch 480/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3212 - acc: 0.8479 - val_loss: 0.4800 - val_acc: 0.7957\n",
      "Epoch 481/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3167 - acc: 0.8445 - val_loss: 0.4672 - val_acc: 0.7957\n",
      "Epoch 482/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.3199 - acc: 0.8489 - val_loss: 0.4659 - val_acc: 0.7975\n",
      "Epoch 483/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3203 - acc: 0.8481 - val_loss: 0.4809 - val_acc: 0.8011\n",
      "Epoch 484/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3206 - acc: 0.8514 - val_loss: 0.4532 - val_acc: 0.7957\n",
      "Epoch 485/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3248 - acc: 0.8459 - val_loss: 0.4736 - val_acc: 0.7940\n",
      "Epoch 486/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3140 - acc: 0.8556 - val_loss: 0.4774 - val_acc: 0.7904\n",
      "Epoch 487/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3187 - acc: 0.8483 - val_loss: 0.4720 - val_acc: 0.7922\n",
      "Epoch 488/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3188 - acc: 0.8493 - val_loss: 0.4733 - val_acc: 0.7957\n",
      "Epoch 489/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3119 - acc: 0.8542 - val_loss: 0.4707 - val_acc: 0.7922\n",
      "Epoch 490/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3136 - acc: 0.8507 - val_loss: 0.4733 - val_acc: 0.8011\n",
      "Epoch 491/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3195 - acc: 0.8499 - val_loss: 0.4555 - val_acc: 0.7993\n",
      "Epoch 492/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3124 - acc: 0.8546 - val_loss: 0.4598 - val_acc: 0.7975\n",
      "Epoch 493/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3149 - acc: 0.8526 - val_loss: 0.4769 - val_acc: 0.7993\n",
      "Epoch 494/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3158 - acc: 0.8508 - val_loss: 0.4673 - val_acc: 0.7886\n",
      "Epoch 495/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3088 - acc: 0.8588 - val_loss: 0.4678 - val_acc: 0.7975\n",
      "Epoch 496/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3115 - acc: 0.8503 - val_loss: 0.4775 - val_acc: 0.7957\n",
      "Epoch 497/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3124 - acc: 0.8560 - val_loss: 0.4643 - val_acc: 0.7975\n",
      "Epoch 498/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3126 - acc: 0.8560 - val_loss: 0.4800 - val_acc: 0.7975\n",
      "Epoch 499/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3242 - acc: 0.8544 - val_loss: 0.4695 - val_acc: 0.7815\n",
      "Epoch 500/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.3187 - acc: 0.8524 - val_loss: 0.4698 - val_acc: 0.7957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3baad08eb8>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=500, batch_size=194, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 - 0s - loss: 0.5255 - acc: 0.7768\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model2.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model2.history.history['acc'])\n",
    "plt.plot(model2.history.history['val_acc'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_116 (Dense)            (None, 300)               10800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 97,852\n",
      "Trainable params: 97,052\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(tf.keras.Input(shape=(35)))\n",
    "model3.add(tf.keras.layers.Dense(300,kernel_initializer=he_init,activation=tf.nn.relu))\n",
    "model3.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
    "model3.add(tf.keras.layers.Dense(200,kernel_initializer=he_init,activation=tf.nn.selu))\n",
    "model3.add(tf.keras.layers.Dropout(0.5))\n",
    "model3.add(tf.keras.layers.Dense(100,kernel_initializer=he_init,activation=tf.nn.relu))\n",
    "model3.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
    "model3.add(tf.keras.layers.Dense(50,kernel_initializer=he_init,activation=tf.nn.selu))\n",
    "model3.add(tf.keras.layers.Dropout(0.5))\n",
    "model3.add(tf.keras.layers.Dense(2))\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5062 samples, validate on 563 samples\n",
      "Epoch 1/500\n",
      "5062/5062 [==============================] - 3s 543us/sample - loss: 0.7789 - acc: 0.6717 - val_loss: 0.5334 - val_acc: 0.7726\n",
      "Epoch 2/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.6338 - acc: 0.7278 - val_loss: 0.4837 - val_acc: 0.7922\n",
      "Epoch 3/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.5649 - acc: 0.7467 - val_loss: 0.4562 - val_acc: 0.7886\n",
      "Epoch 4/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.5264 - acc: 0.7604 - val_loss: 0.4361 - val_acc: 0.7957\n",
      "Epoch 5/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.5128 - acc: 0.7681 - val_loss: 0.4369 - val_acc: 0.8011\n",
      "Epoch 6/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.5108 - acc: 0.7762 - val_loss: 0.4327 - val_acc: 0.7993\n",
      "Epoch 7/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4860 - acc: 0.7728 - val_loss: 0.4305 - val_acc: 0.8046\n",
      "Epoch 8/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4913 - acc: 0.7803 - val_loss: 0.4377 - val_acc: 0.7940\n",
      "Epoch 9/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4726 - acc: 0.7821 - val_loss: 0.4366 - val_acc: 0.7957\n",
      "Epoch 10/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4747 - acc: 0.7793 - val_loss: 0.4256 - val_acc: 0.8046\n",
      "Epoch 11/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4678 - acc: 0.7831 - val_loss: 0.4303 - val_acc: 0.7993\n",
      "Epoch 12/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4661 - acc: 0.7839 - val_loss: 0.4287 - val_acc: 0.8011\n",
      "Epoch 13/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4635 - acc: 0.7859 - val_loss: 0.4237 - val_acc: 0.8064\n",
      "Epoch 14/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4626 - acc: 0.7880 - val_loss: 0.4330 - val_acc: 0.7993\n",
      "Epoch 15/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4610 - acc: 0.7880 - val_loss: 0.4220 - val_acc: 0.8046\n",
      "Epoch 16/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4533 - acc: 0.7878 - val_loss: 0.4268 - val_acc: 0.7957\n",
      "Epoch 17/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4502 - acc: 0.7868 - val_loss: 0.4180 - val_acc: 0.7975\n",
      "Epoch 18/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4494 - acc: 0.7908 - val_loss: 0.4129 - val_acc: 0.8028\n",
      "Epoch 19/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4407 - acc: 0.7947 - val_loss: 0.4182 - val_acc: 0.8046\n",
      "Epoch 20/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4497 - acc: 0.7934 - val_loss: 0.4340 - val_acc: 0.7993\n",
      "Epoch 21/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4394 - acc: 0.7985 - val_loss: 0.4146 - val_acc: 0.8099\n",
      "Epoch 22/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4412 - acc: 0.7967 - val_loss: 0.4165 - val_acc: 0.7869\n",
      "Epoch 23/500\n",
      "5062/5062 [==============================] - 0s 58us/sample - loss: 0.4410 - acc: 0.7951 - val_loss: 0.4331 - val_acc: 0.8011\n",
      "Epoch 24/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4375 - acc: 0.8007 - val_loss: 0.4137 - val_acc: 0.8099\n",
      "Epoch 25/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4441 - acc: 0.7892 - val_loss: 0.4326 - val_acc: 0.8082\n",
      "Epoch 26/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4355 - acc: 0.8040 - val_loss: 0.4278 - val_acc: 0.8064\n",
      "Epoch 27/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4438 - acc: 0.7947 - val_loss: 0.4189 - val_acc: 0.8082\n",
      "Epoch 28/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4349 - acc: 0.7953 - val_loss: 0.4567 - val_acc: 0.8099\n",
      "Epoch 29/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4366 - acc: 0.7971 - val_loss: 0.4563 - val_acc: 0.7993\n",
      "Epoch 30/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4341 - acc: 0.8005 - val_loss: 0.4164 - val_acc: 0.8064\n",
      "Epoch 31/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4356 - acc: 0.7936 - val_loss: 0.4141 - val_acc: 0.7922\n",
      "Epoch 32/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4291 - acc: 0.8024 - val_loss: 0.4277 - val_acc: 0.8028\n",
      "Epoch 33/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4370 - acc: 0.7971 - val_loss: 0.4661 - val_acc: 0.7904\n",
      "Epoch 34/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4398 - acc: 0.7940 - val_loss: 0.4178 - val_acc: 0.8046\n",
      "Epoch 35/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4294 - acc: 0.8021 - val_loss: 0.4198 - val_acc: 0.8064\n",
      "Epoch 36/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4289 - acc: 0.7971 - val_loss: 0.4227 - val_acc: 0.7869\n",
      "Epoch 37/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4336 - acc: 0.7957 - val_loss: 0.4236 - val_acc: 0.7975\n",
      "Epoch 38/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4304 - acc: 0.7989 - val_loss: 0.4297 - val_acc: 0.7975\n",
      "Epoch 39/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4278 - acc: 0.8015 - val_loss: 0.4103 - val_acc: 0.8046\n",
      "Epoch 40/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4272 - acc: 0.8005 - val_loss: 0.4406 - val_acc: 0.8046\n",
      "Epoch 41/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4336 - acc: 0.7985 - val_loss: 0.4529 - val_acc: 0.8028\n",
      "Epoch 42/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4286 - acc: 0.8001 - val_loss: 0.4137 - val_acc: 0.8028\n",
      "Epoch 43/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4271 - acc: 0.7995 - val_loss: 0.4129 - val_acc: 0.7851\n",
      "Epoch 44/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4343 - acc: 0.7987 - val_loss: 0.4241 - val_acc: 0.7904\n",
      "Epoch 45/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4229 - acc: 0.8038 - val_loss: 0.4245 - val_acc: 0.7957\n",
      "Epoch 46/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4298 - acc: 0.8011 - val_loss: 0.4918 - val_acc: 0.7620\n",
      "Epoch 47/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4303 - acc: 0.8068 - val_loss: 0.4159 - val_acc: 0.7993\n",
      "Epoch 48/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4249 - acc: 0.7993 - val_loss: 0.4278 - val_acc: 0.8028\n",
      "Epoch 49/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4329 - acc: 0.8005 - val_loss: 0.4427 - val_acc: 0.7940\n",
      "Epoch 50/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4313 - acc: 0.8032 - val_loss: 0.4157 - val_acc: 0.8064\n",
      "Epoch 51/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4257 - acc: 0.7993 - val_loss: 0.4058 - val_acc: 0.8082\n",
      "Epoch 52/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4205 - acc: 0.8040 - val_loss: 0.4065 - val_acc: 0.7957\n",
      "Epoch 53/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4313 - acc: 0.7999 - val_loss: 0.4326 - val_acc: 0.7957\n",
      "Epoch 54/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4276 - acc: 0.7993 - val_loss: 0.4100 - val_acc: 0.7957\n",
      "Epoch 55/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4153 - acc: 0.8015 - val_loss: 0.4237 - val_acc: 0.7869\n",
      "Epoch 56/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4201 - acc: 0.8038 - val_loss: 0.4956 - val_acc: 0.7052\n",
      "Epoch 57/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4267 - acc: 0.8023 - val_loss: 0.4263 - val_acc: 0.8011\n",
      "Epoch 58/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4247 - acc: 0.7977 - val_loss: 0.4169 - val_acc: 0.7922\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4228 - acc: 0.8052 - val_loss: 0.7254 - val_acc: 0.5524\n",
      "Epoch 60/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4266 - acc: 0.8066 - val_loss: 0.4758 - val_acc: 0.7513\n",
      "Epoch 61/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4267 - acc: 0.8001 - val_loss: 0.4381 - val_acc: 0.7975\n",
      "Epoch 62/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4183 - acc: 0.8076 - val_loss: 0.4045 - val_acc: 0.8082\n",
      "Epoch 63/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4212 - acc: 0.8030 - val_loss: 0.4036 - val_acc: 0.8082\n",
      "Epoch 64/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4184 - acc: 0.8074 - val_loss: 0.4067 - val_acc: 0.7957\n",
      "Epoch 65/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4187 - acc: 0.8040 - val_loss: 0.4211 - val_acc: 0.8046\n",
      "Epoch 66/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4181 - acc: 0.7975 - val_loss: 0.4443 - val_acc: 0.7957\n",
      "Epoch 67/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4182 - acc: 0.8054 - val_loss: 0.4203 - val_acc: 0.8082\n",
      "Epoch 68/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4226 - acc: 0.7997 - val_loss: 0.4220 - val_acc: 0.8064\n",
      "Epoch 69/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4262 - acc: 0.8017 - val_loss: 0.4141 - val_acc: 0.8099\n",
      "Epoch 70/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4240 - acc: 0.8007 - val_loss: 0.4059 - val_acc: 0.7940\n",
      "Epoch 71/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4227 - acc: 0.8070 - val_loss: 0.4352 - val_acc: 0.7957\n",
      "Epoch 72/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4221 - acc: 0.8042 - val_loss: 0.4159 - val_acc: 0.8082\n",
      "Epoch 73/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4193 - acc: 0.8048 - val_loss: 0.4405 - val_acc: 0.7851\n",
      "Epoch 74/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4184 - acc: 0.8056 - val_loss: 0.4071 - val_acc: 0.8028\n",
      "Epoch 75/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4183 - acc: 0.7993 - val_loss: 0.4119 - val_acc: 0.8011\n",
      "Epoch 76/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4234 - acc: 0.8032 - val_loss: 0.4227 - val_acc: 0.7957\n",
      "Epoch 77/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4169 - acc: 0.8074 - val_loss: 0.4443 - val_acc: 0.7993\n",
      "Epoch 78/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4205 - acc: 0.8050 - val_loss: 0.4061 - val_acc: 0.7957\n",
      "Epoch 79/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4173 - acc: 0.8068 - val_loss: 0.4115 - val_acc: 0.8046\n",
      "Epoch 80/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4161 - acc: 0.8030 - val_loss: 0.5036 - val_acc: 0.7087\n",
      "Epoch 81/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4169 - acc: 0.8086 - val_loss: 0.4116 - val_acc: 0.7957\n",
      "Epoch 82/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4139 - acc: 0.8107 - val_loss: 0.4185 - val_acc: 0.8011\n",
      "Epoch 83/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4158 - acc: 0.8084 - val_loss: 0.5285 - val_acc: 0.6856\n",
      "Epoch 84/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4199 - acc: 0.8066 - val_loss: 0.4359 - val_acc: 0.8046\n",
      "Epoch 85/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4150 - acc: 0.8026 - val_loss: 0.4077 - val_acc: 0.8064\n",
      "Epoch 86/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4132 - acc: 0.8090 - val_loss: 0.4213 - val_acc: 0.7975\n",
      "Epoch 87/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4125 - acc: 0.8086 - val_loss: 0.4049 - val_acc: 0.7940\n",
      "Epoch 88/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4154 - acc: 0.8011 - val_loss: 0.4338 - val_acc: 0.7940\n",
      "Epoch 89/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4180 - acc: 0.8032 - val_loss: 0.4107 - val_acc: 0.7993\n",
      "Epoch 90/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4200 - acc: 0.8001 - val_loss: 0.4075 - val_acc: 0.7940\n",
      "Epoch 91/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4177 - acc: 0.8052 - val_loss: 0.4108 - val_acc: 0.7957\n",
      "Epoch 92/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4185 - acc: 0.8044 - val_loss: 0.4782 - val_acc: 0.7513\n",
      "Epoch 93/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4158 - acc: 0.8076 - val_loss: 0.4091 - val_acc: 0.7922\n",
      "Epoch 94/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4167 - acc: 0.8042 - val_loss: 0.4214 - val_acc: 0.8046\n",
      "Epoch 95/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4219 - acc: 0.7983 - val_loss: 0.4081 - val_acc: 0.7975\n",
      "Epoch 96/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4137 - acc: 0.8058 - val_loss: 0.4143 - val_acc: 0.7975\n",
      "Epoch 97/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4140 - acc: 0.8052 - val_loss: 0.4107 - val_acc: 0.8046\n",
      "Epoch 98/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4117 - acc: 0.8062 - val_loss: 0.4152 - val_acc: 0.8028\n",
      "Epoch 99/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4139 - acc: 0.8056 - val_loss: 0.4226 - val_acc: 0.7940\n",
      "Epoch 100/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4139 - acc: 0.8102 - val_loss: 0.4122 - val_acc: 0.7940\n",
      "Epoch 101/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4181 - acc: 0.8076 - val_loss: 0.4225 - val_acc: 0.7993\n",
      "Epoch 102/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4154 - acc: 0.8074 - val_loss: 0.4089 - val_acc: 0.8011\n",
      "Epoch 103/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4157 - acc: 0.8072 - val_loss: 0.4058 - val_acc: 0.8028\n",
      "Epoch 104/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4145 - acc: 0.8074 - val_loss: 0.4273 - val_acc: 0.7993\n",
      "Epoch 105/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4131 - acc: 0.8078 - val_loss: 0.4222 - val_acc: 0.8028\n",
      "Epoch 106/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.4171 - acc: 0.8021 - val_loss: 0.4046 - val_acc: 0.7957\n",
      "Epoch 107/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4129 - acc: 0.8028 - val_loss: 0.4030 - val_acc: 0.7975\n",
      "Epoch 108/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4138 - acc: 0.8019 - val_loss: 0.4028 - val_acc: 0.8011\n",
      "Epoch 109/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4162 - acc: 0.8030 - val_loss: 0.4128 - val_acc: 0.8011\n",
      "Epoch 110/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4153 - acc: 0.8046 - val_loss: 0.4158 - val_acc: 0.8046\n",
      "Epoch 111/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4127 - acc: 0.8096 - val_loss: 0.4051 - val_acc: 0.8064\n",
      "Epoch 112/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.4149 - acc: 0.8056 - val_loss: 0.4126 - val_acc: 0.8028\n",
      "Epoch 113/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4122 - acc: 0.8084 - val_loss: 0.4345 - val_acc: 0.7993\n",
      "Epoch 114/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4138 - acc: 0.8098 - val_loss: 0.4088 - val_acc: 0.8011\n",
      "Epoch 115/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4134 - acc: 0.8072 - val_loss: 0.4058 - val_acc: 0.8028\n",
      "Epoch 116/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4140 - acc: 0.8086 - val_loss: 0.4191 - val_acc: 0.7922\n",
      "Epoch 117/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4149 - acc: 0.8068 - val_loss: 0.4061 - val_acc: 0.7975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4150 - acc: 0.8034 - val_loss: 0.4030 - val_acc: 0.8099\n",
      "Epoch 119/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4151 - acc: 0.8011 - val_loss: 0.4149 - val_acc: 0.8046\n",
      "Epoch 120/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4109 - acc: 0.8072 - val_loss: 0.4014 - val_acc: 0.7957\n",
      "Epoch 121/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4145 - acc: 0.8088 - val_loss: 0.4059 - val_acc: 0.7975\n",
      "Epoch 122/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4149 - acc: 0.8040 - val_loss: 0.4380 - val_acc: 0.7957\n",
      "Epoch 123/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4144 - acc: 0.8060 - val_loss: 0.5146 - val_acc: 0.6980\n",
      "Epoch 124/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4158 - acc: 0.8040 - val_loss: 0.4131 - val_acc: 0.8064\n",
      "Epoch 125/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4101 - acc: 0.8074 - val_loss: 0.4377 - val_acc: 0.7886\n",
      "Epoch 126/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4177 - acc: 0.8068 - val_loss: 0.4330 - val_acc: 0.7922\n",
      "Epoch 127/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4175 - acc: 0.8019 - val_loss: 0.4141 - val_acc: 0.8064\n",
      "Epoch 128/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4157 - acc: 0.8013 - val_loss: 0.4073 - val_acc: 0.8011\n",
      "Epoch 129/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4110 - acc: 0.8098 - val_loss: 0.4229 - val_acc: 0.7940\n",
      "Epoch 130/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4126 - acc: 0.8070 - val_loss: 0.4058 - val_acc: 0.7957\n",
      "Epoch 131/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4120 - acc: 0.8024 - val_loss: 0.4069 - val_acc: 0.7957\n",
      "Epoch 132/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4124 - acc: 0.8084 - val_loss: 0.4067 - val_acc: 0.7940\n",
      "Epoch 133/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4150 - acc: 0.8001 - val_loss: 0.4019 - val_acc: 0.7975\n",
      "Epoch 134/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4137 - acc: 0.8092 - val_loss: 0.4225 - val_acc: 0.7886\n",
      "Epoch 135/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4140 - acc: 0.8062 - val_loss: 0.4044 - val_acc: 0.7904\n",
      "Epoch 136/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4143 - acc: 0.8054 - val_loss: 0.4062 - val_acc: 0.7975\n",
      "Epoch 137/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4117 - acc: 0.8024 - val_loss: 0.4242 - val_acc: 0.8028\n",
      "Epoch 138/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4140 - acc: 0.8021 - val_loss: 0.4033 - val_acc: 0.8064\n",
      "Epoch 139/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4140 - acc: 0.8105 - val_loss: 0.4600 - val_acc: 0.7975\n",
      "Epoch 140/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4145 - acc: 0.8023 - val_loss: 0.4079 - val_acc: 0.8011\n",
      "Epoch 141/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4119 - acc: 0.8054 - val_loss: 0.4021 - val_acc: 0.8011\n",
      "Epoch 142/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4105 - acc: 0.8052 - val_loss: 0.4049 - val_acc: 0.7975\n",
      "Epoch 143/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4125 - acc: 0.8009 - val_loss: 0.4188 - val_acc: 0.7975\n",
      "Epoch 144/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4108 - acc: 0.8054 - val_loss: 0.4080 - val_acc: 0.7904\n",
      "Epoch 145/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4114 - acc: 0.8100 - val_loss: 0.4119 - val_acc: 0.8028\n",
      "Epoch 146/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4121 - acc: 0.8094 - val_loss: 0.4120 - val_acc: 0.8046\n",
      "Epoch 147/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4085 - acc: 0.8064 - val_loss: 0.4784 - val_acc: 0.7425\n",
      "Epoch 148/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4141 - acc: 0.8068 - val_loss: 0.4062 - val_acc: 0.7904\n",
      "Epoch 149/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4092 - acc: 0.8111 - val_loss: 0.4423 - val_acc: 0.7744\n",
      "Epoch 150/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4109 - acc: 0.8062 - val_loss: 0.5057 - val_acc: 0.7034\n",
      "Epoch 151/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4123 - acc: 0.8030 - val_loss: 0.4174 - val_acc: 0.7975\n",
      "Epoch 152/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4105 - acc: 0.8058 - val_loss: 0.4425 - val_acc: 0.7851\n",
      "Epoch 153/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4068 - acc: 0.8111 - val_loss: 0.4281 - val_acc: 0.7851\n",
      "Epoch 154/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4113 - acc: 0.8129 - val_loss: 0.4175 - val_acc: 0.7851\n",
      "Epoch 155/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4075 - acc: 0.8102 - val_loss: 0.4175 - val_acc: 0.7762\n",
      "Epoch 156/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4093 - acc: 0.8092 - val_loss: 0.4172 - val_acc: 0.7940\n",
      "Epoch 157/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4160 - acc: 0.8038 - val_loss: 0.4165 - val_acc: 0.7904\n",
      "Epoch 158/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4120 - acc: 0.8109 - val_loss: 0.4098 - val_acc: 0.7886\n",
      "Epoch 159/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4124 - acc: 0.8092 - val_loss: 0.4133 - val_acc: 0.7957\n",
      "Epoch 160/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4087 - acc: 0.8100 - val_loss: 0.4240 - val_acc: 0.7922\n",
      "Epoch 161/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4119 - acc: 0.8054 - val_loss: 0.4096 - val_acc: 0.7993\n",
      "Epoch 162/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.4121 - acc: 0.8100 - val_loss: 0.4142 - val_acc: 0.8064\n",
      "Epoch 163/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4084 - acc: 0.8096 - val_loss: 0.4160 - val_acc: 0.8028\n",
      "Epoch 164/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4145 - acc: 0.8036 - val_loss: 0.4725 - val_acc: 0.7922\n",
      "Epoch 165/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4167 - acc: 0.8046 - val_loss: 0.4205 - val_acc: 0.7940\n",
      "Epoch 166/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4125 - acc: 0.8104 - val_loss: 0.4085 - val_acc: 0.8064\n",
      "Epoch 167/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4128 - acc: 0.8098 - val_loss: 0.4309 - val_acc: 0.8046\n",
      "Epoch 168/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4115 - acc: 0.8076 - val_loss: 0.4327 - val_acc: 0.7993\n",
      "Epoch 169/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4115 - acc: 0.8040 - val_loss: 0.4090 - val_acc: 0.7993\n",
      "Epoch 170/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.4099 - acc: 0.8096 - val_loss: 0.4079 - val_acc: 0.7993\n",
      "Epoch 171/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.4087 - acc: 0.8078 - val_loss: 0.4275 - val_acc: 0.7975\n",
      "Epoch 172/500\n",
      "5062/5062 [==============================] - 0s 61us/sample - loss: 0.4081 - acc: 0.8098 - val_loss: 0.4099 - val_acc: 0.8011\n",
      "Epoch 173/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4083 - acc: 0.8080 - val_loss: 0.4340 - val_acc: 0.7798\n",
      "Epoch 174/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4122 - acc: 0.8096 - val_loss: 0.4675 - val_acc: 0.7442\n",
      "Epoch 175/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4095 - acc: 0.8123 - val_loss: 0.4101 - val_acc: 0.7975\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.4073 - acc: 0.8105 - val_loss: 0.4060 - val_acc: 0.7833\n",
      "Epoch 177/500\n",
      "5062/5062 [==============================] - 0s 58us/sample - loss: 0.4076 - acc: 0.8129 - val_loss: 0.4076 - val_acc: 0.7975\n",
      "Epoch 178/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.4101 - acc: 0.8107 - val_loss: 0.4261 - val_acc: 0.7886\n",
      "Epoch 179/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4092 - acc: 0.8090 - val_loss: 0.4100 - val_acc: 0.8028\n",
      "Epoch 180/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4111 - acc: 0.8100 - val_loss: 0.4136 - val_acc: 0.7869\n",
      "Epoch 181/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4103 - acc: 0.8076 - val_loss: 0.4152 - val_acc: 0.7940\n",
      "Epoch 182/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.4073 - acc: 0.8133 - val_loss: 0.4687 - val_acc: 0.7496\n",
      "Epoch 183/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4106 - acc: 0.8060 - val_loss: 0.4350 - val_acc: 0.7922\n",
      "Epoch 184/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4086 - acc: 0.8109 - val_loss: 0.4149 - val_acc: 0.7922\n",
      "Epoch 185/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4111 - acc: 0.8052 - val_loss: 0.4261 - val_acc: 0.7780\n",
      "Epoch 186/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4120 - acc: 0.8072 - val_loss: 0.4113 - val_acc: 0.7975\n",
      "Epoch 187/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4098 - acc: 0.8074 - val_loss: 0.4110 - val_acc: 0.7957\n",
      "Epoch 188/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4094 - acc: 0.8102 - val_loss: 0.4103 - val_acc: 0.7993\n",
      "Epoch 189/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4077 - acc: 0.8078 - val_loss: 0.4312 - val_acc: 0.7904\n",
      "Epoch 190/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4074 - acc: 0.8111 - val_loss: 0.4123 - val_acc: 0.7922\n",
      "Epoch 191/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4159 - acc: 0.8056 - val_loss: 0.4365 - val_acc: 0.7726\n",
      "Epoch 192/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4098 - acc: 0.8135 - val_loss: 0.4160 - val_acc: 0.7940\n",
      "Epoch 193/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4051 - acc: 0.8092 - val_loss: 0.4173 - val_acc: 0.7975\n",
      "Epoch 194/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4084 - acc: 0.8127 - val_loss: 0.4084 - val_acc: 0.7975\n",
      "Epoch 195/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4096 - acc: 0.8078 - val_loss: 0.4975 - val_acc: 0.7194\n",
      "Epoch 196/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4145 - acc: 0.8070 - val_loss: 0.4034 - val_acc: 0.7940\n",
      "Epoch 197/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4094 - acc: 0.8127 - val_loss: 0.4112 - val_acc: 0.7975\n",
      "Epoch 198/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4060 - acc: 0.8109 - val_loss: 0.4125 - val_acc: 0.8028\n",
      "Epoch 199/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4076 - acc: 0.8133 - val_loss: 0.4245 - val_acc: 0.8064\n",
      "Epoch 200/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4028 - acc: 0.8141 - val_loss: 0.4157 - val_acc: 0.7940\n",
      "Epoch 201/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4095 - acc: 0.8123 - val_loss: 0.4235 - val_acc: 0.7975\n",
      "Epoch 202/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4028 - acc: 0.8167 - val_loss: 0.4131 - val_acc: 0.8117\n",
      "Epoch 203/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4028 - acc: 0.8127 - val_loss: 0.4103 - val_acc: 0.8011\n",
      "Epoch 204/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4087 - acc: 0.8098 - val_loss: 0.4316 - val_acc: 0.7993\n",
      "Epoch 205/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4094 - acc: 0.8100 - val_loss: 0.4285 - val_acc: 0.8064\n",
      "Epoch 206/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4087 - acc: 0.8076 - val_loss: 0.4284 - val_acc: 0.7922\n",
      "Epoch 207/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4019 - acc: 0.8096 - val_loss: 0.4074 - val_acc: 0.7815\n",
      "Epoch 208/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4050 - acc: 0.8125 - val_loss: 0.4087 - val_acc: 0.7940\n",
      "Epoch 209/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4045 - acc: 0.8092 - val_loss: 0.4045 - val_acc: 0.8046\n",
      "Epoch 210/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4047 - acc: 0.8119 - val_loss: 0.4041 - val_acc: 0.8011\n",
      "Epoch 211/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4080 - acc: 0.8080 - val_loss: 0.4189 - val_acc: 0.7957\n",
      "Epoch 212/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4124 - acc: 0.8115 - val_loss: 0.4233 - val_acc: 0.8046\n",
      "Epoch 213/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4047 - acc: 0.8104 - val_loss: 0.4088 - val_acc: 0.8082\n",
      "Epoch 214/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4049 - acc: 0.8135 - val_loss: 0.4456 - val_acc: 0.7869\n",
      "Epoch 215/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4032 - acc: 0.8127 - val_loss: 0.4143 - val_acc: 0.7940\n",
      "Epoch 216/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4069 - acc: 0.8105 - val_loss: 0.4074 - val_acc: 0.7815\n",
      "Epoch 217/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4008 - acc: 0.8127 - val_loss: 0.4124 - val_acc: 0.7957\n",
      "Epoch 218/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4058 - acc: 0.8115 - val_loss: 0.4069 - val_acc: 0.7904\n",
      "Epoch 219/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4030 - acc: 0.8111 - val_loss: 0.5117 - val_acc: 0.6980\n",
      "Epoch 220/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4059 - acc: 0.8143 - val_loss: 0.4605 - val_acc: 0.7496\n",
      "Epoch 221/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4068 - acc: 0.8113 - val_loss: 0.4107 - val_acc: 0.7993\n",
      "Epoch 222/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4100 - acc: 0.8046 - val_loss: 0.4126 - val_acc: 0.8011\n",
      "Epoch 223/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4059 - acc: 0.8139 - val_loss: 0.4141 - val_acc: 0.7940\n",
      "Epoch 224/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4023 - acc: 0.8109 - val_loss: 0.4376 - val_acc: 0.7975\n",
      "Epoch 225/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4078 - acc: 0.8070 - val_loss: 0.4032 - val_acc: 0.8028\n",
      "Epoch 226/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4045 - acc: 0.8105 - val_loss: 0.4056 - val_acc: 0.8046\n",
      "Epoch 227/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4013 - acc: 0.8153 - val_loss: 0.4105 - val_acc: 0.7940\n",
      "Epoch 228/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4056 - acc: 0.8143 - val_loss: 0.4515 - val_acc: 0.7922\n",
      "Epoch 229/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4068 - acc: 0.8111 - val_loss: 0.4103 - val_acc: 0.7904\n",
      "Epoch 230/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4022 - acc: 0.8115 - val_loss: 0.4369 - val_acc: 0.7851\n",
      "Epoch 231/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4037 - acc: 0.8143 - val_loss: 0.4149 - val_acc: 0.7975\n",
      "Epoch 232/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4039 - acc: 0.8096 - val_loss: 0.4386 - val_acc: 0.7833\n",
      "Epoch 233/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4035 - acc: 0.8119 - val_loss: 0.4054 - val_acc: 0.7940\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4050 - acc: 0.8104 - val_loss: 0.4277 - val_acc: 0.7975\n",
      "Epoch 235/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4024 - acc: 0.8133 - val_loss: 0.4087 - val_acc: 0.7904\n",
      "Epoch 236/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4029 - acc: 0.8105 - val_loss: 0.4093 - val_acc: 0.7904\n",
      "Epoch 237/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4039 - acc: 0.8135 - val_loss: 0.4843 - val_acc: 0.7922\n",
      "Epoch 238/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4061 - acc: 0.8094 - val_loss: 0.4052 - val_acc: 0.7940\n",
      "Epoch 239/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4009 - acc: 0.8151 - val_loss: 0.4150 - val_acc: 0.7922\n",
      "Epoch 240/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4050 - acc: 0.8096 - val_loss: 0.4570 - val_acc: 0.7869\n",
      "Epoch 241/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4045 - acc: 0.8117 - val_loss: 0.4105 - val_acc: 0.7993\n",
      "Epoch 242/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4005 - acc: 0.8141 - val_loss: 0.4147 - val_acc: 0.7780\n",
      "Epoch 243/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3990 - acc: 0.8151 - val_loss: 0.4152 - val_acc: 0.7993\n",
      "Epoch 244/500\n",
      "5062/5062 [==============================] - 0s 61us/sample - loss: 0.4000 - acc: 0.8155 - val_loss: 0.4173 - val_acc: 0.7886\n",
      "Epoch 245/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4004 - acc: 0.8129 - val_loss: 0.4069 - val_acc: 0.7957\n",
      "Epoch 246/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4016 - acc: 0.8088 - val_loss: 0.4280 - val_acc: 0.7886\n",
      "Epoch 247/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4006 - acc: 0.8151 - val_loss: 0.4132 - val_acc: 0.8028\n",
      "Epoch 248/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.4034 - acc: 0.8133 - val_loss: 0.4212 - val_acc: 0.7957\n",
      "Epoch 249/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3975 - acc: 0.8179 - val_loss: 0.4334 - val_acc: 0.7886\n",
      "Epoch 250/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4008 - acc: 0.8129 - val_loss: 0.4159 - val_acc: 0.7851\n",
      "Epoch 251/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3972 - acc: 0.8163 - val_loss: 0.4132 - val_acc: 0.7957\n",
      "Epoch 252/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4000 - acc: 0.8186 - val_loss: 0.4119 - val_acc: 0.7940\n",
      "Epoch 253/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3962 - acc: 0.8177 - val_loss: 0.4293 - val_acc: 0.7975\n",
      "Epoch 254/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4014 - acc: 0.8147 - val_loss: 0.4112 - val_acc: 0.8099\n",
      "Epoch 255/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4004 - acc: 0.8129 - val_loss: 0.4209 - val_acc: 0.7904\n",
      "Epoch 256/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4032 - acc: 0.8141 - val_loss: 0.4269 - val_acc: 0.7851\n",
      "Epoch 257/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4014 - acc: 0.8131 - val_loss: 0.4582 - val_acc: 0.7726\n",
      "Epoch 258/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4048 - acc: 0.8036 - val_loss: 0.4327 - val_acc: 0.7922\n",
      "Epoch 259/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4005 - acc: 0.8151 - val_loss: 0.4112 - val_acc: 0.7940\n",
      "Epoch 260/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3987 - acc: 0.8111 - val_loss: 0.4300 - val_acc: 0.7922\n",
      "Epoch 261/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4036 - acc: 0.8105 - val_loss: 0.4217 - val_acc: 0.7975\n",
      "Epoch 262/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3964 - acc: 0.8105 - val_loss: 0.4106 - val_acc: 0.7886\n",
      "Epoch 263/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4004 - acc: 0.8147 - val_loss: 0.4571 - val_acc: 0.7584\n",
      "Epoch 264/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4020 - acc: 0.8084 - val_loss: 0.4274 - val_acc: 0.7922\n",
      "Epoch 265/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4013 - acc: 0.8147 - val_loss: 0.4131 - val_acc: 0.7940\n",
      "Epoch 266/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4062 - acc: 0.8127 - val_loss: 0.4272 - val_acc: 0.8028\n",
      "Epoch 267/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4049 - acc: 0.8104 - val_loss: 0.4071 - val_acc: 0.7993\n",
      "Epoch 268/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4022 - acc: 0.8147 - val_loss: 0.4331 - val_acc: 0.7957\n",
      "Epoch 269/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3988 - acc: 0.8173 - val_loss: 0.4200 - val_acc: 0.7940\n",
      "Epoch 270/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4030 - acc: 0.8133 - val_loss: 0.4248 - val_acc: 0.7833\n",
      "Epoch 271/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4072 - acc: 0.8115 - val_loss: 0.4064 - val_acc: 0.7975\n",
      "Epoch 272/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4106 - acc: 0.8119 - val_loss: 0.4234 - val_acc: 0.7886\n",
      "Epoch 273/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4108 - acc: 0.8100 - val_loss: 0.4103 - val_acc: 0.8011\n",
      "Epoch 274/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4048 - acc: 0.8135 - val_loss: 0.4086 - val_acc: 0.7993\n",
      "Epoch 275/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4036 - acc: 0.8084 - val_loss: 0.4306 - val_acc: 0.7975\n",
      "Epoch 276/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.4035 - acc: 0.8107 - val_loss: 0.4314 - val_acc: 0.7940\n",
      "Epoch 277/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4046 - acc: 0.8153 - val_loss: 0.4108 - val_acc: 0.7904\n",
      "Epoch 278/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.4021 - acc: 0.8115 - val_loss: 0.4131 - val_acc: 0.8046\n",
      "Epoch 279/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3974 - acc: 0.8183 - val_loss: 0.4076 - val_acc: 0.7869\n",
      "Epoch 280/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4008 - acc: 0.8141 - val_loss: 0.4107 - val_acc: 0.7957\n",
      "Epoch 281/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4017 - acc: 0.8131 - val_loss: 0.4240 - val_acc: 0.7922\n",
      "Epoch 282/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4008 - acc: 0.8121 - val_loss: 0.4071 - val_acc: 0.7957\n",
      "Epoch 283/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4026 - acc: 0.8161 - val_loss: 0.4189 - val_acc: 0.7975\n",
      "Epoch 284/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3969 - acc: 0.8173 - val_loss: 0.4211 - val_acc: 0.7957\n",
      "Epoch 285/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4033 - acc: 0.8149 - val_loss: 0.4141 - val_acc: 0.7957\n",
      "Epoch 286/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4006 - acc: 0.8165 - val_loss: 0.4197 - val_acc: 0.7922\n",
      "Epoch 287/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4027 - acc: 0.8117 - val_loss: 0.4670 - val_acc: 0.7940\n",
      "Epoch 288/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4017 - acc: 0.8113 - val_loss: 0.4195 - val_acc: 0.7993\n",
      "Epoch 289/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4018 - acc: 0.8111 - val_loss: 0.4177 - val_acc: 0.7851\n",
      "Epoch 290/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4026 - acc: 0.8121 - val_loss: 0.5346 - val_acc: 0.7833\n",
      "Epoch 291/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4014 - acc: 0.8169 - val_loss: 0.4145 - val_acc: 0.7975\n",
      "Epoch 292/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4060 - acc: 0.8100 - val_loss: 0.4592 - val_acc: 0.7940\n",
      "Epoch 293/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.4019 - acc: 0.8105 - val_loss: 0.4296 - val_acc: 0.7975\n",
      "Epoch 294/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3987 - acc: 0.8175 - val_loss: 0.4317 - val_acc: 0.7904\n",
      "Epoch 295/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3991 - acc: 0.8143 - val_loss: 0.4326 - val_acc: 0.7957\n",
      "Epoch 296/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3974 - acc: 0.8179 - val_loss: 0.5005 - val_acc: 0.7798\n",
      "Epoch 297/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4110 - acc: 0.8054 - val_loss: 0.4219 - val_acc: 0.8117\n",
      "Epoch 298/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4033 - acc: 0.8135 - val_loss: 0.4164 - val_acc: 0.8011\n",
      "Epoch 299/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3957 - acc: 0.8171 - val_loss: 0.4212 - val_acc: 0.7975\n",
      "Epoch 300/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3970 - acc: 0.8159 - val_loss: 0.4113 - val_acc: 0.7940\n",
      "Epoch 301/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3983 - acc: 0.8113 - val_loss: 0.4269 - val_acc: 0.8011\n",
      "Epoch 302/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3930 - acc: 0.8153 - val_loss: 0.4378 - val_acc: 0.7798\n",
      "Epoch 303/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3968 - acc: 0.8157 - val_loss: 0.4433 - val_acc: 0.7904\n",
      "Epoch 304/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3984 - acc: 0.8147 - val_loss: 0.4187 - val_acc: 0.8028\n",
      "Epoch 305/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3992 - acc: 0.8127 - val_loss: 0.5054 - val_acc: 0.7034\n",
      "Epoch 306/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3991 - acc: 0.8171 - val_loss: 0.4126 - val_acc: 0.7957\n",
      "Epoch 307/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3987 - acc: 0.8171 - val_loss: 0.4422 - val_acc: 0.7833\n",
      "Epoch 308/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3983 - acc: 0.8163 - val_loss: 0.4124 - val_acc: 0.7975\n",
      "Epoch 309/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3997 - acc: 0.8149 - val_loss: 0.4453 - val_acc: 0.7975\n",
      "Epoch 310/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3963 - acc: 0.8222 - val_loss: 0.4132 - val_acc: 0.8011\n",
      "Epoch 311/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3995 - acc: 0.8123 - val_loss: 0.4278 - val_acc: 0.7993\n",
      "Epoch 312/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3965 - acc: 0.8188 - val_loss: 0.4662 - val_acc: 0.7709\n",
      "Epoch 313/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4018 - acc: 0.8167 - val_loss: 0.4314 - val_acc: 0.7851\n",
      "Epoch 314/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4010 - acc: 0.8167 - val_loss: 0.4099 - val_acc: 0.7869\n",
      "Epoch 315/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3991 - acc: 0.8147 - val_loss: 0.4101 - val_acc: 0.7940\n",
      "Epoch 316/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3950 - acc: 0.8200 - val_loss: 0.4290 - val_acc: 0.8028\n",
      "Epoch 317/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3985 - acc: 0.8137 - val_loss: 0.4670 - val_acc: 0.7904\n",
      "Epoch 318/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3971 - acc: 0.8151 - val_loss: 0.4237 - val_acc: 0.7904\n",
      "Epoch 319/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4025 - acc: 0.8133 - val_loss: 0.4369 - val_acc: 0.7957\n",
      "Epoch 320/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4064 - acc: 0.8137 - val_loss: 0.4188 - val_acc: 0.7975\n",
      "Epoch 321/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4023 - acc: 0.8155 - val_loss: 0.4087 - val_acc: 0.7922\n",
      "Epoch 322/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3968 - acc: 0.8188 - val_loss: 0.4173 - val_acc: 0.7940\n",
      "Epoch 323/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4023 - acc: 0.8121 - val_loss: 0.5251 - val_acc: 0.6803\n",
      "Epoch 324/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4052 - acc: 0.8127 - val_loss: 0.4260 - val_acc: 0.8011\n",
      "Epoch 325/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4051 - acc: 0.8090 - val_loss: 0.4100 - val_acc: 0.7993\n",
      "Epoch 326/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4022 - acc: 0.8149 - val_loss: 0.4234 - val_acc: 0.7940\n",
      "Epoch 327/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3949 - acc: 0.8210 - val_loss: 0.4102 - val_acc: 0.7993\n",
      "Epoch 328/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3992 - acc: 0.8159 - val_loss: 0.4113 - val_acc: 0.7993\n",
      "Epoch 329/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3959 - acc: 0.8169 - val_loss: 0.4120 - val_acc: 0.7940\n",
      "Epoch 330/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3980 - acc: 0.8165 - val_loss: 0.4456 - val_acc: 0.7993\n",
      "Epoch 331/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4008 - acc: 0.8141 - val_loss: 0.4155 - val_acc: 0.8046\n",
      "Epoch 332/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3992 - acc: 0.8194 - val_loss: 0.4281 - val_acc: 0.7957\n",
      "Epoch 333/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3960 - acc: 0.8145 - val_loss: 0.4489 - val_acc: 0.7886\n",
      "Epoch 334/500\n",
      "5062/5062 [==============================] - 0s 60us/sample - loss: 0.4037 - acc: 0.8098 - val_loss: 0.4610 - val_acc: 0.7993\n",
      "Epoch 335/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4012 - acc: 0.8157 - val_loss: 0.4088 - val_acc: 0.7975\n",
      "Epoch 336/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4005 - acc: 0.8143 - val_loss: 0.4041 - val_acc: 0.7975\n",
      "Epoch 337/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4021 - acc: 0.8163 - val_loss: 0.4116 - val_acc: 0.7922\n",
      "Epoch 338/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4100 - acc: 0.8074 - val_loss: 0.4098 - val_acc: 0.8082\n",
      "Epoch 339/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3997 - acc: 0.8135 - val_loss: 0.4089 - val_acc: 0.7886\n",
      "Epoch 340/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4008 - acc: 0.8151 - val_loss: 0.4722 - val_acc: 0.7993\n",
      "Epoch 341/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3984 - acc: 0.8188 - val_loss: 0.4174 - val_acc: 0.7940\n",
      "Epoch 342/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3959 - acc: 0.8129 - val_loss: 0.4123 - val_acc: 0.7904\n",
      "Epoch 343/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4016 - acc: 0.8169 - val_loss: 0.4185 - val_acc: 0.7922\n",
      "Epoch 344/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3987 - acc: 0.8183 - val_loss: 0.4211 - val_acc: 0.7957\n",
      "Epoch 345/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3989 - acc: 0.8165 - val_loss: 0.4172 - val_acc: 0.7833\n",
      "Epoch 346/500\n",
      "5062/5062 [==============================] - 0s 48us/sample - loss: 0.4022 - acc: 0.8155 - val_loss: 0.4706 - val_acc: 0.7957\n",
      "Epoch 347/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4013 - acc: 0.8133 - val_loss: 0.4058 - val_acc: 0.7957\n",
      "Epoch 348/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3976 - acc: 0.8163 - val_loss: 0.4188 - val_acc: 0.7940\n",
      "Epoch 349/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3978 - acc: 0.8183 - val_loss: 0.4088 - val_acc: 0.7993\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4016 - acc: 0.8127 - val_loss: 0.4184 - val_acc: 0.7975\n",
      "Epoch 351/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4038 - acc: 0.8137 - val_loss: 0.4171 - val_acc: 0.7851\n",
      "Epoch 352/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4021 - acc: 0.8155 - val_loss: 0.4287 - val_acc: 0.8064\n",
      "Epoch 353/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3924 - acc: 0.8190 - val_loss: 0.4257 - val_acc: 0.7904\n",
      "Epoch 354/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4023 - acc: 0.8109 - val_loss: 0.4078 - val_acc: 0.7993\n",
      "Epoch 355/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3963 - acc: 0.8171 - val_loss: 0.4149 - val_acc: 0.7904\n",
      "Epoch 356/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4011 - acc: 0.8129 - val_loss: 0.4244 - val_acc: 0.7886\n",
      "Epoch 357/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4067 - acc: 0.8100 - val_loss: 0.4154 - val_acc: 0.7940\n",
      "Epoch 358/500\n",
      "5062/5062 [==============================] - 0s 47us/sample - loss: 0.4014 - acc: 0.8096 - val_loss: 0.4120 - val_acc: 0.7940\n",
      "Epoch 359/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4026 - acc: 0.8135 - val_loss: 0.4567 - val_acc: 0.7851\n",
      "Epoch 360/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3993 - acc: 0.8143 - val_loss: 0.4189 - val_acc: 0.7940\n",
      "Epoch 361/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3991 - acc: 0.8157 - val_loss: 0.4194 - val_acc: 0.7904\n",
      "Epoch 362/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4014 - acc: 0.8159 - val_loss: 0.4134 - val_acc: 0.7922\n",
      "Epoch 363/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3975 - acc: 0.8194 - val_loss: 0.4161 - val_acc: 0.7975\n",
      "Epoch 364/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3959 - acc: 0.8155 - val_loss: 0.4234 - val_acc: 0.7904\n",
      "Epoch 365/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3955 - acc: 0.8188 - val_loss: 0.4183 - val_acc: 0.7886\n",
      "Epoch 366/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4016 - acc: 0.8143 - val_loss: 0.4198 - val_acc: 0.7922\n",
      "Epoch 367/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.4001 - acc: 0.8171 - val_loss: 0.4247 - val_acc: 0.7922\n",
      "Epoch 368/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3980 - acc: 0.8179 - val_loss: 0.4204 - val_acc: 0.7851\n",
      "Epoch 369/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3964 - acc: 0.8214 - val_loss: 0.5071 - val_acc: 0.7034\n",
      "Epoch 370/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3956 - acc: 0.8202 - val_loss: 0.4129 - val_acc: 0.7993\n",
      "Epoch 371/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.3996 - acc: 0.8139 - val_loss: 0.4211 - val_acc: 0.7922\n",
      "Epoch 372/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3989 - acc: 0.8145 - val_loss: 0.4491 - val_acc: 0.7886\n",
      "Epoch 373/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3957 - acc: 0.8169 - val_loss: 0.4212 - val_acc: 0.7940\n",
      "Epoch 374/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3928 - acc: 0.8161 - val_loss: 0.4198 - val_acc: 0.8011\n",
      "Epoch 375/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3931 - acc: 0.8226 - val_loss: 0.4185 - val_acc: 0.7922\n",
      "Epoch 376/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3953 - acc: 0.8179 - val_loss: 0.4145 - val_acc: 0.8028\n",
      "Epoch 377/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3957 - acc: 0.8155 - val_loss: 0.4388 - val_acc: 0.7869\n",
      "Epoch 378/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3989 - acc: 0.8113 - val_loss: 0.4171 - val_acc: 0.7851\n",
      "Epoch 379/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4007 - acc: 0.8139 - val_loss: 0.4135 - val_acc: 0.7957\n",
      "Epoch 380/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3972 - acc: 0.8151 - val_loss: 0.4240 - val_acc: 0.7869\n",
      "Epoch 381/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3951 - acc: 0.8200 - val_loss: 0.4152 - val_acc: 0.7975\n",
      "Epoch 382/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3913 - acc: 0.8224 - val_loss: 0.4642 - val_acc: 0.7602\n",
      "Epoch 383/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3967 - acc: 0.8190 - val_loss: 0.4243 - val_acc: 0.7957\n",
      "Epoch 384/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3962 - acc: 0.8147 - val_loss: 0.4163 - val_acc: 0.7940\n",
      "Epoch 385/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3956 - acc: 0.8200 - val_loss: 0.4792 - val_acc: 0.7425\n",
      "Epoch 386/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.4008 - acc: 0.8192 - val_loss: 0.4322 - val_acc: 0.7940\n",
      "Epoch 387/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.4042 - acc: 0.8129 - val_loss: 0.4314 - val_acc: 0.8028\n",
      "Epoch 388/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3963 - acc: 0.8208 - val_loss: 0.4510 - val_acc: 0.7851\n",
      "Epoch 389/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3976 - acc: 0.8157 - val_loss: 0.4191 - val_acc: 0.8028\n",
      "Epoch 390/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3945 - acc: 0.8200 - val_loss: 0.4276 - val_acc: 0.8011\n",
      "Epoch 391/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3952 - acc: 0.8173 - val_loss: 0.4142 - val_acc: 0.7975\n",
      "Epoch 392/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3943 - acc: 0.8183 - val_loss: 0.4206 - val_acc: 0.7957\n",
      "Epoch 393/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3938 - acc: 0.8173 - val_loss: 0.4203 - val_acc: 0.7940\n",
      "Epoch 394/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3946 - acc: 0.8181 - val_loss: 0.4222 - val_acc: 0.7869\n",
      "Epoch 395/500\n",
      "5062/5062 [==============================] - 0s 60us/sample - loss: 0.3950 - acc: 0.8153 - val_loss: 0.4209 - val_acc: 0.7886\n",
      "Epoch 396/500\n",
      "5062/5062 [==============================] - 0s 61us/sample - loss: 0.3964 - acc: 0.8125 - val_loss: 0.4174 - val_acc: 0.7904\n",
      "Epoch 397/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3891 - acc: 0.8214 - val_loss: 0.4175 - val_acc: 0.7957\n",
      "Epoch 398/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3980 - acc: 0.8173 - val_loss: 0.4678 - val_acc: 0.7886\n",
      "Epoch 399/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3955 - acc: 0.8188 - val_loss: 0.4335 - val_acc: 0.7922\n",
      "Epoch 400/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.3944 - acc: 0.8196 - val_loss: 0.4256 - val_acc: 0.7851\n",
      "Epoch 401/500\n",
      "5062/5062 [==============================] - 0s 56us/sample - loss: 0.3967 - acc: 0.8175 - val_loss: 0.4168 - val_acc: 0.7904\n",
      "Epoch 402/500\n",
      "5062/5062 [==============================] - 0s 58us/sample - loss: 0.3946 - acc: 0.8192 - val_loss: 0.4209 - val_acc: 0.7993\n",
      "Epoch 403/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3933 - acc: 0.8200 - val_loss: 0.4573 - val_acc: 0.7904\n",
      "Epoch 404/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3984 - acc: 0.8151 - val_loss: 0.4300 - val_acc: 0.7922\n",
      "Epoch 405/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3962 - acc: 0.8186 - val_loss: 0.4102 - val_acc: 0.7975\n",
      "Epoch 406/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3964 - acc: 0.8169 - val_loss: 0.4133 - val_acc: 0.7975\n",
      "Epoch 407/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3952 - acc: 0.8183 - val_loss: 0.4575 - val_acc: 0.7922\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3913 - acc: 0.8192 - val_loss: 0.4142 - val_acc: 0.8099\n",
      "Epoch 409/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3908 - acc: 0.8202 - val_loss: 0.4265 - val_acc: 0.7940\n",
      "Epoch 410/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3966 - acc: 0.8208 - val_loss: 0.4233 - val_acc: 0.8011\n",
      "Epoch 411/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3974 - acc: 0.8210 - val_loss: 0.4191 - val_acc: 0.8046\n",
      "Epoch 412/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3975 - acc: 0.8143 - val_loss: 0.4307 - val_acc: 0.7993\n",
      "Epoch 413/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.3910 - acc: 0.8196 - val_loss: 0.4137 - val_acc: 0.8064\n",
      "Epoch 414/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3950 - acc: 0.8163 - val_loss: 0.4224 - val_acc: 0.8028\n",
      "Epoch 415/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3954 - acc: 0.8169 - val_loss: 0.4160 - val_acc: 0.8046\n",
      "Epoch 416/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3977 - acc: 0.8165 - val_loss: 0.4173 - val_acc: 0.7957\n",
      "Epoch 417/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3955 - acc: 0.8159 - val_loss: 0.4184 - val_acc: 0.7957\n",
      "Epoch 418/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3938 - acc: 0.8198 - val_loss: 0.4220 - val_acc: 0.7975\n",
      "Epoch 419/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3924 - acc: 0.8222 - val_loss: 0.4120 - val_acc: 0.8011\n",
      "Epoch 420/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3952 - acc: 0.8179 - val_loss: 0.4204 - val_acc: 0.7940\n",
      "Epoch 421/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3924 - acc: 0.8196 - val_loss: 0.4246 - val_acc: 0.7922\n",
      "Epoch 422/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3943 - acc: 0.8190 - val_loss: 0.4344 - val_acc: 0.8011\n",
      "Epoch 423/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3975 - acc: 0.8185 - val_loss: 0.4317 - val_acc: 0.7975\n",
      "Epoch 424/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3967 - acc: 0.8161 - val_loss: 0.4215 - val_acc: 0.7957\n",
      "Epoch 425/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3950 - acc: 0.8200 - val_loss: 0.4351 - val_acc: 0.8028\n",
      "Epoch 426/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3955 - acc: 0.8181 - val_loss: 0.4253 - val_acc: 0.8028\n",
      "Epoch 427/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3942 - acc: 0.8159 - val_loss: 0.4167 - val_acc: 0.7922\n",
      "Epoch 428/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3994 - acc: 0.8102 - val_loss: 0.4064 - val_acc: 0.7993\n",
      "Epoch 429/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3958 - acc: 0.8185 - val_loss: 0.4351 - val_acc: 0.7886\n",
      "Epoch 430/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3971 - acc: 0.8123 - val_loss: 0.4177 - val_acc: 0.7904\n",
      "Epoch 431/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3945 - acc: 0.8196 - val_loss: 0.4144 - val_acc: 0.7975\n",
      "Epoch 432/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3932 - acc: 0.8149 - val_loss: 0.4729 - val_acc: 0.7886\n",
      "Epoch 433/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3967 - acc: 0.8117 - val_loss: 0.4248 - val_acc: 0.7922\n",
      "Epoch 434/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3928 - acc: 0.8171 - val_loss: 0.4287 - val_acc: 0.7975\n",
      "Epoch 435/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3938 - acc: 0.8149 - val_loss: 0.4479 - val_acc: 0.7957\n",
      "Epoch 436/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3967 - acc: 0.8179 - val_loss: 0.4426 - val_acc: 0.7957\n",
      "Epoch 437/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3929 - acc: 0.8204 - val_loss: 0.4401 - val_acc: 0.7815\n",
      "Epoch 438/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3973 - acc: 0.8115 - val_loss: 0.4154 - val_acc: 0.7815\n",
      "Epoch 439/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3968 - acc: 0.8163 - val_loss: 0.4204 - val_acc: 0.7886\n",
      "Epoch 440/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3952 - acc: 0.8204 - val_loss: 0.4412 - val_acc: 0.7886\n",
      "Epoch 441/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3931 - acc: 0.8171 - val_loss: 0.4401 - val_acc: 0.7975\n",
      "Epoch 442/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3940 - acc: 0.8157 - val_loss: 0.4237 - val_acc: 0.7940\n",
      "Epoch 443/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3885 - acc: 0.8198 - val_loss: 0.4219 - val_acc: 0.7904\n",
      "Epoch 444/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3959 - acc: 0.8133 - val_loss: 0.4656 - val_acc: 0.7886\n",
      "Epoch 445/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3964 - acc: 0.8143 - val_loss: 0.4776 - val_acc: 0.7567\n",
      "Epoch 446/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3992 - acc: 0.8188 - val_loss: 0.4209 - val_acc: 0.7886\n",
      "Epoch 447/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3992 - acc: 0.8139 - val_loss: 0.4728 - val_acc: 0.7584\n",
      "Epoch 448/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3908 - acc: 0.8204 - val_loss: 0.4163 - val_acc: 0.7957\n",
      "Epoch 449/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3908 - acc: 0.8196 - val_loss: 0.4186 - val_acc: 0.7833\n",
      "Epoch 450/500\n",
      "5062/5062 [==============================] - 0s 55us/sample - loss: 0.3930 - acc: 0.8153 - val_loss: 0.4142 - val_acc: 0.7957\n",
      "Epoch 451/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3943 - acc: 0.8190 - val_loss: 0.4335 - val_acc: 0.7957\n",
      "Epoch 452/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3928 - acc: 0.8159 - val_loss: 0.4124 - val_acc: 0.7886\n",
      "Epoch 453/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3940 - acc: 0.8163 - val_loss: 0.4186 - val_acc: 0.7940\n",
      "Epoch 454/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3879 - acc: 0.8208 - val_loss: 0.4236 - val_acc: 0.8011\n",
      "Epoch 455/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3928 - acc: 0.8198 - val_loss: 0.4386 - val_acc: 0.7886\n",
      "Epoch 456/500\n",
      "5062/5062 [==============================] - 0s 49us/sample - loss: 0.4015 - acc: 0.8131 - val_loss: 0.4082 - val_acc: 0.7886\n",
      "Epoch 457/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.4007 - acc: 0.8159 - val_loss: 0.4468 - val_acc: 0.7798\n",
      "Epoch 458/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3953 - acc: 0.8163 - val_loss: 0.4288 - val_acc: 0.7904\n",
      "Epoch 459/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3994 - acc: 0.8109 - val_loss: 0.4210 - val_acc: 0.7922\n",
      "Epoch 460/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3956 - acc: 0.8163 - val_loss: 0.4407 - val_acc: 0.7904\n",
      "Epoch 461/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3962 - acc: 0.8175 - val_loss: 0.4604 - val_acc: 0.7957\n",
      "Epoch 462/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3931 - acc: 0.8214 - val_loss: 0.4654 - val_acc: 0.7638\n",
      "Epoch 463/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3974 - acc: 0.8165 - val_loss: 0.4208 - val_acc: 0.7975\n",
      "Epoch 464/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3897 - acc: 0.8198 - val_loss: 0.4352 - val_acc: 0.7869\n",
      "Epoch 465/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3954 - acc: 0.8192 - val_loss: 0.4167 - val_acc: 0.7940\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3970 - acc: 0.8183 - val_loss: 0.4226 - val_acc: 0.8028\n",
      "Epoch 467/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3924 - acc: 0.8175 - val_loss: 0.4233 - val_acc: 0.7957\n",
      "Epoch 468/500\n",
      "5062/5062 [==============================] - 0s 57us/sample - loss: 0.3921 - acc: 0.8198 - val_loss: 0.4226 - val_acc: 0.7922\n",
      "Epoch 469/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3954 - acc: 0.8141 - val_loss: 0.4297 - val_acc: 0.7975\n",
      "Epoch 470/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3914 - acc: 0.8163 - val_loss: 0.4143 - val_acc: 0.7922\n",
      "Epoch 471/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3904 - acc: 0.8194 - val_loss: 0.4412 - val_acc: 0.7904\n",
      "Epoch 472/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3919 - acc: 0.8145 - val_loss: 0.4612 - val_acc: 0.7957\n",
      "Epoch 473/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3876 - acc: 0.8222 - val_loss: 0.4312 - val_acc: 0.7940\n",
      "Epoch 474/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3905 - acc: 0.8198 - val_loss: 0.4239 - val_acc: 0.8064\n",
      "Epoch 475/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3896 - acc: 0.8222 - val_loss: 0.4322 - val_acc: 0.8046\n",
      "Epoch 476/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3916 - acc: 0.8194 - val_loss: 0.4225 - val_acc: 0.7922\n",
      "Epoch 477/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3891 - acc: 0.8208 - val_loss: 0.4413 - val_acc: 0.8064\n",
      "Epoch 478/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3893 - acc: 0.8240 - val_loss: 0.4205 - val_acc: 0.7904\n",
      "Epoch 479/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3894 - acc: 0.8179 - val_loss: 0.4208 - val_acc: 0.7993\n",
      "Epoch 480/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3916 - acc: 0.8173 - val_loss: 0.4322 - val_acc: 0.8064\n",
      "Epoch 481/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3938 - acc: 0.8139 - val_loss: 0.4446 - val_acc: 0.7975\n",
      "Epoch 482/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3956 - acc: 0.8175 - val_loss: 0.4317 - val_acc: 0.7957\n",
      "Epoch 483/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3905 - acc: 0.8218 - val_loss: 0.4164 - val_acc: 0.7886\n",
      "Epoch 484/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3958 - acc: 0.8185 - val_loss: 0.4190 - val_acc: 0.7957\n",
      "Epoch 485/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3941 - acc: 0.8192 - val_loss: 0.4205 - val_acc: 0.7975\n",
      "Epoch 486/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3958 - acc: 0.8167 - val_loss: 0.4191 - val_acc: 0.7975\n",
      "Epoch 487/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3925 - acc: 0.8185 - val_loss: 0.4490 - val_acc: 0.8046\n",
      "Epoch 488/500\n",
      "5062/5062 [==============================] - 0s 54us/sample - loss: 0.3946 - acc: 0.8210 - val_loss: 0.4323 - val_acc: 0.7940\n",
      "Epoch 489/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3951 - acc: 0.8147 - val_loss: 0.4234 - val_acc: 0.8028\n",
      "Epoch 490/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3890 - acc: 0.8192 - val_loss: 0.4444 - val_acc: 0.8028\n",
      "Epoch 491/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3925 - acc: 0.8171 - val_loss: 0.4209 - val_acc: 0.7957\n",
      "Epoch 492/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3895 - acc: 0.8208 - val_loss: 0.4287 - val_acc: 0.8011\n",
      "Epoch 493/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3885 - acc: 0.8222 - val_loss: 0.4185 - val_acc: 0.8011\n",
      "Epoch 494/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3918 - acc: 0.8206 - val_loss: 0.4237 - val_acc: 0.7957\n",
      "Epoch 495/500\n",
      "5062/5062 [==============================] - 0s 52us/sample - loss: 0.3919 - acc: 0.8167 - val_loss: 0.4645 - val_acc: 0.7904\n",
      "Epoch 496/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3910 - acc: 0.8198 - val_loss: 0.4264 - val_acc: 0.7869\n",
      "Epoch 497/500\n",
      "5062/5062 [==============================] - 0s 53us/sample - loss: 0.3934 - acc: 0.8202 - val_loss: 0.4306 - val_acc: 0.7957\n",
      "Epoch 498/500\n",
      "5062/5062 [==============================] - 0s 50us/sample - loss: 0.3918 - acc: 0.8200 - val_loss: 0.4185 - val_acc: 0.7922\n",
      "Epoch 499/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3929 - acc: 0.8183 - val_loss: 0.4481 - val_acc: 0.7940\n",
      "Epoch 500/500\n",
      "5062/5062 [==============================] - 0s 51us/sample - loss: 0.3932 - acc: 0.8206 - val_loss: 0.4246 - val_acc: 0.7975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ba49a1fd0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train, y_train, epochs=500, batch_size=194, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 - 0s - loss: 0.4563 - acc: 0.7832\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model3.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
